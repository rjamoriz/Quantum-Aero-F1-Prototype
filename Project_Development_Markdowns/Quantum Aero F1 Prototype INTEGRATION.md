Ther eis# Q-Aero Integration Plan: Quantum-Enhanced Aerodynamic Optimization Platform**Version:** 1.0**Date:** 2025-11-24**Project:** Quantum-Aero F1 Prototype**Status:** Integration Planning Phase---## Table of Contents1. [Executive Summary](#executive-summary)2. [Architecture Overview](#architecture-overview)3. [Requirements Synthesis](#requirements-synthesis)4. [Design Integration](#design-integration)5. [Development Plan](#development-plan)6. [Complex Components Handling](#complex-components-handling)7. [Implementation Guidelines](#implementation-guidelines)8. [Integration Checkpoints](#integration-checkpoints)9. [Traceability Matrix](#traceability-matrix)10. [Development Workflow](#development-workflow)11. [Synthetic Data Generation & Visualization](#synthetic-data-generation--visualization)12. [Local Development Setup (RTX 4070 Proof of Concept)](#local-development-setup-rtx-4070-proof-of-concept)13. [Production-Ready Docker & Microservices Architecture](#production-ready-docker--microservices-architecture)14. [Risk Register](#risk-register)15. [Deployment Strategy](#deployment-strategy)---## Executive Summary### Project OverviewThe Quantum-Aero F1 Prototype is a cutting-edge aerodynamic optimization platform that combines three revolutionary technologies:1. **Quantum Computing** - QUBO/QAOA optimization for combinatorial design space exploration2. **Machine Learning** - GPU-accelerated surrogate models for real-time aerodynamic predictions3. **Physics-Based Simulation** - Multi-fidelity CFD/FSI for validation and training data generation**Target Users:** F1 teams, aerodynamic engineers, computational researchers**Development Environment:** VS Codespaces with Docker containerization**Timeline:** 16-22 weeks to production deployment**Budget:** Open-source tools + cloud infrastructure (NVIDIA GPU required)### Key Integration Goals1. **Microservice Interoperability** - Seamless communication between ML, physics, quantum, and backend services2. **Performance at Scale** - <100ms ML inference, <2s full simulation, <10 quantum optimization iterations3. **Multi-Fidelity Pipeline** - Automatic escalation from surrogate ÔåÆ medium-fidelity ÔåÆ high-fidelity validation4. **Real-Time Visualization** - Interactive 3D aerodynamic field rendering with Three.js/VTK.js5. **Production Readiness** - Docker orchestration, JWT authentication, MongoDB persistence, CI/CD pipeline### Success Criteria| Category | Metric | Target | Status ||----------|--------|--------|--------|| **Performance** | ML inference latency | <100ms on RTX 4070 | Pending || **Performance** | Full simulation time | Ôëñ2 seconds | Pending || **Accuracy** | Surrogate model error | <5% vs. CFD | Pending || **Quantum** | QAOA convergence | <10 iterations | Pending || **Integration** | End-to-end workflow | Functional | Pending || **Deployment** | All services running | Docker compose | Pending || **Validation** | Physical test correlation | ┬▒10% | Future |### Strategic Value Proposition- **Speed:** 1000x faster design iteration vs. traditional CFD workflows- **Innovation:** Quantum-discovered geometries impossible via classical methods- **Cost:** 50% reduction in wind tunnel testing expenses- **Performance:** +5-8% downforce improvement by 2027 (Genius_Evolution.md:304)- **Safety:** Comprehensive aeroelastic flutter analysis and prevention---## Architecture Overview### System Architecture Diagram```mermaidflowchart TB    subgraph Frontend["Frontend Layer (Next.js + React)"]        UI[3D Visualization<br/>Three.js + VTK.js]        DASH[Dashboards & Controls]        AUTH[Authentication UI]    end    subgraph Backend["Backend Orchestration (Node.js + Express)"]        API[REST/GraphQL API]        ORCH[Job Orchestration]        JWT[JWT Authentication]    end    subgraph Microservices["Microservice Layer"]        ML[ML Inference Service<br/>PyTorch/ONNX GPU]        PHYS[Physics Service<br/>VLM/Panel Methods]        QUANT[Quantum Optimizer<br/>Qiskit QAOA]        FSI[FSI Service<br/>OpenFOAM+CalculiX]    end    subgraph Data["Data Layer"]        MONGO[(MongoDB)]        CACHE[(Redis Cache)]    end    UI --> API    DASH --> API    AUTH --> JWT    API --> ORCH    ORCH --> ML    ORCH --> PHYS    ORCH --> QUANT    ORCH --> FSI    ML --> MONGO    PHYS --> MONGO    QUANT --> MONGO    FSI --> MONGO    ML -.-> CACHE    PHYS -.-> CACHE    style ML fill:#8b5cf6,stroke:#6d28d9,stroke-width:2px,color:#fff    style QUANT fill:#f59e0b,stroke:#d97706,stroke-width:3px,color:#000    style FSI fill:#ef4444,stroke:#dc2626,stroke-width:2px,color:#fff    style PHYS fill:#10b981,stroke:#059669,stroke-width:2px,color:#fff```### Component Relationships#### Primary Data Flow```mermaidsequenceDiagram    participant User    participant Frontend    participant Backend    participant ML Service    participant Quantum Service    participant Physics Service    participant Database    User->>Frontend: Upload mesh + parameters    Frontend->>Backend: POST /api/optimize    Backend->>ML Service: Predict initial aerodynamics    ML Service-->>Backend: Pressure/force predictions    Backend->>Quantum Service: Optimize design variables (QUBO)    Quantum Service-->>Backend: Optimal configuration    Backend->>Physics Service: Validate with VLM    Physics Service-->>Backend: Validated results    Backend->>Database: Store simulation    Backend-->>Frontend: Results + 3D data    Frontend-->>User: Visualize fields```#### Multi-Fidelity Escalation Flow```mermaidflowchart LR    A[Design Input] --> B[Low-Fidelity<br/>ML Surrogate<br/>~100ms]    B --> C{Confidence > 90%?}    C -->|Yes| D[Accept Design]    C -->|No| E[Medium-Fidelity<br/>VLM/Panel<br/>~10s]    E --> F{Top 10% Candidate?}    F -->|Yes| G[High-Fidelity<br/>FSI Validation<br/>~6hrs]    F -->|No| H[Reject Design]    G --> I{Physical Plausible?}    I -->|Yes| J[Deploy to Production]    I -->|No| K[Update Surrogate]    K --> B    style B fill:#8b5cf6,stroke:#6d28d9,stroke-width:2px,color:#fff    style E fill:#3b82f6,stroke:#1d4ed8,stroke-width:2px,color:#fff    style G fill:#ef4444,stroke:#dc2626,stroke-width:2px,color:#fff```### Technology Stack#### Frontend Stack| Component | Technology | Version | Purpose ||-----------|-----------|---------|---------|| **Framework** | Next.js | 14+ | React framework with SSR || **UI Library** | React | 18+ | Component-based UI || **3D Rendering** | Three.js | Latest | WebGL 3D visualization || **Flow Viz** | VTK.js | Latest | Scientific visualization || **Styling** | TailwindCSS | 3+ | Utility-first CSS || **State Management** | Redux Toolkit | 2+ | Global state || **Charts** | Recharts | 2+ | Real-time KPI charts |**Reference:** Quantum-Aero F1 Prototype DESIGN.md:106-112#### Backend Stack| Component | Technology | Version | Purpose ||-----------|-----------|---------|---------|| **Runtime** | Node.js | 20+ | JavaScript runtime || **Framework** | Express.js | 4+ | Web server framework || **API** | GraphQL (Apollo) | Latest | Flexible query API || **Database** | MongoDB | 7+ | Document storage || **Auth** | JWT | Latest | Token authentication || **Caching** | Redis | 7+ | High-speed cache || **Queue** | Bull | Latest | Job queue management |**Reference:** Quantum-Aero F1 Prototype DESIGN.md:114-119#### ML/AI Stack| Component | Technology | Version | Purpose ||-----------|-----------|---------|---------|| **Framework** | PyTorch | 2.0+ | Deep learning || **Acceleration** | CUDA | 11.8+ | GPU computation || **Inference** | ONNX Runtime GPU | Latest | Production inference || **Architecture** | GNN/Geo-CNN | Custom | Mesh-based learning || **Training** | Mixed Precision | - | FP16/FP32 training || **Data** | NumPy/Pandas | Latest | Data processing |**Reference:** Quantum-Aero F1 Prototype DESIGN.md:120-124#### Quantum Stack| Component | Technology | Version | Purpose ||-----------|-----------|---------|---------|| **Framework** | Qiskit | 1.0+ | Quantum circuits || **Simulator** | Qiskit Aer | Latest | Local simulation || **Algorithm** | QAOA | - | Quantum optimization || **Annealing** | D-Wave Ocean SDK | Latest | Quantum annealing || **Classical** | SciPy | Latest | Hybrid classical solver || **VQE** | PennyLane | Latest | Variational quantum |**Reference:** Quantum-Aero F1 Prototype DESIGN.md:125-129, Genius_Evolution.md:152-189#### Physics Stack| Component | Technology | Version | Purpose ||-----------|-----------|---------|---------|| **CFD** | OpenFOAM | 10+ | High-fidelity CFD || **FEM** | CalculiX / Code_Aster | Latest | Structural analysis || **Coupling** | preCICE | 3+ | FSI coupling || **VLM** | Custom Python | - | Vortex lattice method || **Panel** | Custom Python | - | Panel method || **Mesh** | trimesh / PyMesh | Latest | Mesh processing |**Reference:** Quantum-Aero F1 Prototype AEROELASTIC.md:138-150, COMPLEX TRANSIENT.md:193-210#### DevOps Stack| Component | Technology | Version | Purpose ||-----------|-----------|---------|---------|| **Containers** | Docker | 24+ | Containerization || **Orchestration** | Docker Compose | 2+ | Multi-container apps || **GPU Support** | NVIDIA Container Toolkit | Latest | GPU in containers || **Proxy** | NGINX | 1.24+ | Reverse proxy || **Monitoring** | Prometheus + Grafana | Latest | Observability || **Logging** | ELK Stack | 8+ | Centralized logging || **CI/CD** | GitHub Actions | - | Automation |**Reference:** Quantum-Aero F1 Prototype DESIGN.md:130-135---## Requirements Synthesis### Functional Requirements#### FR-1: Aerodynamic Prediction**Source:** Quantum-Aero F1 Prototype TASKS.md:11, DESIGN.md:40-44**Description:** System shall predict aerodynamic fields (pressure, vorticity, forces) for arbitrary 3D geometries.**Acceptance Criteria:**- [ ] Accept STL/OBJ mesh input- [ ] Preprocess mesh to structured tensor format- [ ] Predict pressure distribution with <5% error vs. CFD- [ ] Predict drag/downforce coefficients with <2% error- [ ] Return results in <100ms on RTX 4070**Traceability:** ÔåÆ Design FR-1 ÔåÆ Implementation Phase 1.3, Phase 3 ÔåÆ Testing TC-ML-01---#### FR-2: Physics-Based Validation**Source:** Quantum-Aero F1 Prototype TASKS.md:14-17, DESIGN.md:47-51**Description:** System shall validate ML predictions using physics-based VLM and Panel methods.**Acceptance Criteria:**- [ ] Implement VLM solver for lifting surfaces- [ ] Implement Panel method for pressure fields- [ ] Validate on standard NACA airfoils- [ ] Compute aerodynamic coefficients within ┬▒10% of wind tunnel data- [ ] Cache results for repeated geometries**Traceability:** ÔåÆ Design FR-2 ÔåÆ Implementation Phase 1.2 ÔåÆ Testing TC-PHYS-01---#### FR-3: Quantum Optimization**Source:** Quantum-Aero F1 Prototype TASKS.md:43-47, COMPLEX TRANSIENT.md:284-325**Description:** System shall optimize aerodynamic designs using quantum algorithms (QAOA/VQE).**Acceptance Criteria:**- [ ] Encode design variables as QUBO binary formulation- [ ] Support multi-objective optimization (downforce, drag, flutter margin, mass)- [ ] Implement QAOA with warm-start initialization- [ ] Integrate Qiskit Aer simulator backend- [ ] Converge to optimal solution in <10 iterations- [ ] Support 20-50 qubit problems**Traceability:** ÔåÆ Design FR-3 ÔåÆ Implementation Phase 4 ÔåÆ Testing TC-QUANT-01---#### FR-4: Aeroelastic Analysis**Source:** Quantum-Aero F1 Prototype AEROELASTIC.md:11-67, COMPLEX TRANSIENT.md:9-149**Description:** System shall analyze fluid-structure interaction and predict aeroelastic phenomena (flutter, buffeting, VIV).**Acceptance Criteria:**- [ ] Compute structural modal analysis (natural frequencies, mode shapes)- [ ] Predict flutter speed with ┬▒5% accuracy- [ ] Analyze transient aerodynamics during corner exit, DRS activation- [ ] Compute modal damping vs. speed (V-g diagram)- [ ] Flag designs with insufficient flutter margin (Vf < 1.2 ├ù Vmax)**Traceability:** ÔåÆ Design FR-4 ÔåÆ Implementation Phase 4.3 ÔåÆ Testing TC-FSI-01---#### FR-5: 3D Visualization**Source:** Quantum-Aero F1 Prototype TASKS.md:104-107, DESIGN.md:26-30**Description:** System shall render interactive 3D visualizations of aerodynamic fields.**Acceptance Criteria:**- [ ] Display 3D mesh with pressure colormap- [ ] Visualize vorticity fields with VTK.js- [ ] Interactive camera controls (orbit, pan, zoom)- [ ] Real-time field updates (<100ms refresh)- [ ] Export visualizations as images/videos**Traceability:** ÔåÆ Design FR-5 ÔåÆ Implementation Phase 5.2 ÔåÆ Testing TC-UI-01---#### FR-6: Job Orchestration**Source:** Quantum-Aero F1 Prototype TASKS.md:49-54, DESIGN.md:33-37**Description:** Backend shall orchestrate multi-service workflows and manage simulation jobs.**Acceptance Criteria:**- [ ] Queue simulation jobs with priority- [ ] Coordinate calls to ML, physics, quantum services- [ ] Track job status (pending, running, completed, failed)- [ ] Retry failed jobs with exponential backoff- [ ] Store results in MongoDB with metadata**Traceability:** ÔåÆ Design FR-6 ÔåÆ Implementation Phase 2.4 ÔåÆ Testing TC-ORCH-01---#### FR-7: User Authentication**Source:** Quantum-Aero F1 Prototype DESIGN.md:54, DESIGN.md:91**Description:** System shall authenticate users and authorize access to resources.**Acceptance Criteria:**- [ ] JWT-based authentication- [ ] Role-based access control (admin, engineer, viewer)- [ ] Secure password hashing (bcrypt)- [ ] Session management with token refresh- [ ] HTTPS encryption for all API calls**Traceability:** ÔåÆ Design FR-7 ÔåÆ Implementation Phase 2.4 ÔåÆ Testing TC-AUTH-01---### Non-Functional Requirements#### NFR-1: Performance**Source:** Quantum-Aero F1 Prototype DESIGN.md:97-102, PLAN.md:94| Metric | Requirement | Measurement Method ||--------|-------------|-------------------|| **ML Inference** | <100ms on RTX 4070 | Benchmark with representative mesh || **Full Simulation** | Ôëñ2 seconds per pass | End-to-end timing || **Quantum Optimization** | <10 iterations | QAOA convergence tracking || **UI Response** | <100ms user interaction | Frontend performance profiling || **Database Query** | <50ms average | MongoDB slow query log || **API Latency** | <200ms P95 | Prometheus metrics |**Traceability:** ÔåÆ NFR-1 ÔåÆ Load Testing ÔåÆ Performance Dashboard---#### NFR-2: Scalability**Source:** Quantum-Aero F1 Prototype DESIGN.md:5-19**Requirements:**- [ ] Horizontal scaling of microservices via Docker Compose- [ ] GPU workload batching for multiple concurrent requests- [ ] Redis caching for repeated mesh evaluations- [ ] MongoDB sharding for large datasets (future)- [ ] Handle 100+ concurrent users (future)**Traceability:** ÔåÆ NFR-2 ÔåÆ Stress Testing ÔåÆ Capacity Planning---#### NFR-3: Reliability**Source:** Quantum-Aero F1 Prototype PLAN.md:92-97**Requirements:**- [ ] 99% uptime for production services- [ ] Automatic service restart on failure (Docker restart policy)- [ ] Data backup every 24 hours- [ ] Graceful degradation (fallback to classical optimization if quantum fails)- [ ] Health checks for all microservices**Traceability:** ÔåÆ NFR-3 ÔåÆ Reliability Testing ÔåÆ SLA Monitoring---#### NFR-4: Security**Source:** Quantum-Aero F1 Prototype DESIGN.md:89-93**Requirements:**- [ ] All services isolated in Docker network- [ ] JWT authentication with token expiration- [ ] HTTPS/TLS for all external communication- [ ] Resource caps for GPU jobs (prevent DoS)- [ ] Input validation and sanitization- [ ] No secrets in source code (use environment variables)**Traceability:** ÔåÆ NFR-4 ÔåÆ Security Testing ÔåÆ Vulnerability Scan---#### NFR-5: Maintainability**Requirements:**- [ ] Comprehensive API documentation (Swagger/OpenAPI)- [ ] Code coverage >80% for critical paths- [ ] Logging at INFO/WARN/ERROR levels- [ ] Prometheus metrics for all services- [ ] Clear error messages and stack traces**Traceability:** ÔåÆ NFR-5 ÔåÆ Code Quality ÔåÆ Technical Debt---#### NFR-6: Usability**Source:** Quantum-Aero F1 Prototype TASKS.md:98-113**Requirements:**- [ ] Dark-mode UI for reduced eye strain- [ ] Intuitive simulation parameter controls- [ ] Real-time progress indicators for long-running jobs- [ ] Contextual help and tooltips- [ ] Responsive design (desktop/tablet)**Traceability:** ÔåÆ NFR-6 ÔåÆ Usability Testing ÔåÆ UX Feedback---### Integration-Specific Requirements#### INT-1: API Contracts**Description:** All microservices shall expose well-defined REST APIs with versioning.**Specification:**```yamlML Inference Service:  POST /api/v1/predict-pressure    Input: { mesh: File, velocity: float, yaw: float }    Output: { pressure_field: Array, confidence: float }  POST /api/v1/predict-forces    Input: { mesh: File, velocity: float }    Output: { Cl: float, Cd: float, L_D_ratio: float }Physics Service:  POST /api/v1/vlm-solve    Input: { mesh: File, velocity: float, alpha: float }    Output: { forces: Vector3, moments: Vector3, circulation: Array }  POST /api/v1/panel-solve    Input: { mesh: File, velocity: float }    Output: { pressure: Array, cp_distribution: Array }Quantum Service:  POST /api/v1/optimize    Input: { qubo_matrix: Array, constraints: Object, method: "QAOA" | "VQE" }    Output: { solution: Array, energy: float, iterations: int }```**Reference:** Quantum-Aero F1 Prototype DESIGN.md:33-58---#### INT-2: Data Models**Description:** Standardized data schemas for cross-service communication.**MongoDB Collections:**```javascript// simulations collection{  _id: ObjectId,  userId: ObjectId,  meshId: ObjectId,  parameters: {    velocity: Number,    yaw: Number,    rideHeight: Number,    drsState: String  },  results: {    ml_prediction: Object,    physics_validation: Object,    quantum_optimization: Object  },  metadata: {    created: Date,    duration: Number,    status: String  }}// designs collection{  _id: ObjectId,  name: String,  geometry: {    meshUrl: String,    vertices: Number,    faces: Number  },  aeroelastic: {    flutterSpeed: Number,    naturalFrequencies: [Number],    modeShapes: [Array]  },  performance: {    Cl: Number,    Cd: Number,    L_D: Number  }}```**Reference:** Quantum-Aero F1 Prototype DESIGN.md:61-66---#### INT-3: Error Handling**Description:** Consistent error codes and propagation across services.**Error Code Schema:**| Code | Category | Description | Recovery Action ||------|----------|-------------|----------------|| 1000-1999 | Client Errors | Invalid input, auth failure | Retry with valid data || 2000-2999 | Server Errors | Internal service failure | Retry with backoff || 3000-3999 | ML Service | Model inference failure | Fallback to physics || 4000-4999 | Quantum Service | QAOA convergence failure | Use classical optimizer || 5000-5999 | Physics Service | Solver divergence | Reduce timestep, remesh |---### Constraints and Limitations#### Hardware Constraints**Source:** Quantum-Aero F1 Prototype TASKS.md:147-152- **NVIDIA GPU Required:** RTX 3060 or higher (CUDA 11.8+)- **VRAM:** Minimum 8GB for ML inference, 16GB+ recommended- **CPU:** 8+ cores for physics service- **RAM:** 32GB minimum, 64GB recommended- **Storage:** 500GB SSD for datasets and results---#### Software Constraints- **Docker Required:** Version 24+ with NVIDIA Container Toolkit- **Python Version:** 3.11+ (for PyTorch compatibility)- **Node.js Version:** 20+ (for backend services)- **MongoDB:** Version 7+ (for aggregation pipeline features)---#### Quantum Computing Constraints**Source:** Genius_Evolution.md:133-149- **Qubit Count:** Limited to 20-30 qubits on Qiskit Aer simulator- **Circuit Depth:** QAOA layers constrained by noise- **Annealing Variables:** D-Wave supports 5000+ variables but requires embedding- **Simulation Time:** Exponential growth with qubit count---#### Regulatory Constraints**Source:** Genius_Evolution.md:342-347- **FIA Technical Regulations:** All designs must comply with 2027 F1 rules- **IP Protection:** Patent quantum optimization algorithms- **Data Security:** Encrypted telemetry and design data---## Design Integration### Unified Design Principles**Source:** Quantum-Aero F1 Prototype DESIGN.md:1-71. **Microservice Independence** - Each service can be developed, deployed, and scaled independently2. **API-First Design** - All services expose RESTful APIs before implementation3. **Multi-Fidelity by Default** - Always use surrogate first, escalate to high-fidelity only when needed4. **Fail-Safe Degradation** - System continues operation with reduced functionality if services fail5. **Observable by Design** - All services emit metrics, logs, and traces6. **GPU-Accelerated** - Leverage CUDA for all computationally intensive operations7. **Physics-Informed ML** - Incorporate conservation laws into loss functions---### Interface Specifications#### ML Inference Service API**Endpoint:** `/api/v1/predict-pressure`**Method:** POST**Headers:**```Content-Type: multipart/form-dataAuthorization: Bearer <JWT_TOKEN>```**Request Body:**```json{  "mesh": "<binary STL file>",  "velocity": 250.0,  "yaw": 3.0,  "rideHeight": -5.0,  "returnConfidence": true}```**Response (200 OK):**```json{  "success": true,  "data": {    "pressure_field": [[x, y, z, p], ...],    "confidence": 0.95,    "inferenceTime": 87,    "modelVersion": "v2.1.0"  }}```**Response (400 Bad Request):**```json{  "success": false,  "error": {    "code": 1001,    "message": "Invalid mesh format. Expected STL or OBJ.",    "details": "File contains non-manifold geometry"  }}```**Reference:** Quantum-Aero F1 Prototype DESIGN.md:40-44---#### Quantum Optimization Service API**Endpoint:** `/api/v1/optimize`**Method:** POST**Request Body:**```json{  "method": "QAOA",  "qubo": {    "Q": [[0, -1, -1], [-1, 0, -1], [-1, -1, 0]],    "offset": 0  },  "constraints": {    "maxIterations": 100,    "convergenceThreshold": 1e-6,    "layers": 3  },  "warmStart": {    "enabled": true,    "initialState": [1, 0, 1]  }}```**Response (200 OK):**```json{  "success": true,  "data": {    "solution": [1, 0, 1],    "energy": -3.14159,    "iterations": 47,    "convergenceAchieved": true,    "executionTime": 8.3,    "backend": "qiskit_aer_simulator"  }}```**Reference:** Quantum-Aero F1 Prototype COMPLEX TRANSIENT.md:309-325---### Data Exchange Formats#### Mesh Format (STL)**Standard:** ISO 10303-21 (STEP) or Binary STL**Validation Rules:**- Manifold geometry (no gaps, no self-intersections)- Consistent vertex winding (right-hand rule)- Maximum 1M triangles for real-time processing- Maximum file size: 100MB**Preprocessing Pipeline:**```python# Mesh preprocessing exampledef preprocess_mesh(stl_file):    mesh = trimesh.load(stl_file)    # 1. Validate manifold    assert mesh.is_watertight, "Mesh must be watertight"    # 2. Normalize scale    mesh.apply_scale(1.0 / mesh.scale)    # 3. Center at origin    mesh.vertices -= mesh.centroid    # 4. Convert to tensor    vertices = torch.tensor(mesh.vertices, dtype=torch.float32)    faces = torch.tensor(mesh.faces, dtype=torch.long)    return vertices, faces```---#### Aerodynamic Field Format**Format:** HDF5 for large fields, JSON for small datasets**HDF5 Structure:**```simulation_001.h5Ôö£ÔöÇÔöÇ /geometryÔöé   Ôö£ÔöÇÔöÇ vertices [N, 3]Ôöé   ÔööÔöÇÔöÇ faces [M, 3]Ôö£ÔöÇÔöÇ /fieldsÔöé   Ôö£ÔöÇÔöÇ pressure [N]Ôöé   Ôö£ÔöÇÔöÇ velocity [N, 3]Ôöé   ÔööÔöÇÔöÇ vorticity [N, 3]Ôö£ÔöÇÔöÇ /forcesÔöé   Ôö£ÔöÇÔöÇ dragÔöé   Ôö£ÔöÇÔöÇ liftÔöé   ÔööÔöÇÔöÇ moment [3]ÔööÔöÇÔöÇ /metadata    Ôö£ÔöÇÔöÇ timestamp    Ôö£ÔöÇÔöÇ velocity    ÔööÔöÇÔöÇ solver```---### API Contracts**Contract Testing Strategy:**1. **Pact Testing** - Consumer-driven contract tests2. **OpenAPI Spec** - Generate Swagger docs from code3. **Version Control** - Semantic versioning (v1, v2, etc.)4. **Backward Compatibility** - Support N-1 versions during migration**Example Contract Test:**```javascript// Example Pact test for ML servicedescribe('ML Inference Service', () => {  it('should predict pressure field', async () => {    const response = await fetch('/api/v1/predict-pressure', {      method: 'POST',      body: formData    });    expect(response.status).toBe(200);    expect(response.data).toHaveProperty('pressure_field');    expect(response.data.pressure_field).toBeArray();    expect(response.data.confidence).toBeGreaterThan(0.5);  });});```---## Development Plan### Phase Breakdown with Milestones#### Phase 1: Foundation (Weeks 1-3)**Goal:** Establish core infrastructure and baseline capabilities**Reference:** Quantum-Aero F1 Prototype PLAN.md:44-49, TASKS.md:5-24##### Week 1: Development Environment Setup**Milestone M1.1: Environment Ready**- [x] Initialize Git repository- [ ] Configure VS Codespaces with Docker support- [ ] Install NVIDIA Container Toolkit- [ ] Set up Python 3.11 environment with PyTorch CUDA- [ ] Set up Node.js 20 environment- [ ] Configure MongoDB 7 container- [ ] Create docker-compose.yml skeleton**Deliverable:** Development environment documentation**Owner:** DevOps Lead**Status:** In Progress---##### Week 2: Dataset Acquisition & Physics Engine**Milestone M1.2: Physics Baseline Operational****Tasks (from TASKS.md:7-11):**- [ ] Identify aerodynamic datasets (NASA, CFD open sets)- [ ] Preprocess meshes (STL/OBJ) to standardized format- [ ] Define input/output spaces for ML surrogate**Tasks (from TASKS.md:14-17):**- [ ] Implement VLM (Vortex Lattice Method) solver- [ ] Add Panel Method for pressure field computation- [ ] Validate on standard NACA airfoils (0012, 4412, 6409)- [ ] Compare results with published wind tunnel data (┬▒10% target)**Deliverable:**- Preprocessed dataset (100+ meshes)- VLM/Panel solver validated on NACA airfoils- Validation report**Owner:** Physics Team**Status:** Pending**Blocker:** None---##### Week 3: ML Model Architecture**Milestone M1.3: Surrogate Model Architecture Defined****Tasks (from TASKS.md:19-24):**- [ ] Define PyTorch CUDA model architecture (GNN or Geo-CNN)- [ ] Build training pipeline with data loaders- [ ] Set up data augmentation (rotation, scaling, noise injection)- [ ] Implement physics-informed loss function (continuity + momentum)- [ ] Create checkpoint manager for model versioning**Deliverable:**- Model architecture code- Training pipeline- Physics-informed loss implementation**Owner:** ML Team**Status:** Pending**Dependency:** M1.2 (need dataset)---#### Phase 2: Microservice Layer (Weeks 4-6)**Goal:** Build and integrate all microservices**Reference:** Quantum-Aero F1 Prototype PLAN.md:50-54, TASKS.md:27-56##### Week 4: ML Inference & Physics Services**Milestone M2.1: ML and Physics APIs Operational****ML Service Tasks (TASKS.md:29-34):**- [ ] Build FastAPI server for ML inference- [ ] Integrate ONNX Runtime GPU for production inference- [ ] Add request batching scheduler (batch size: 8-16)- [ ] Expose `/predict-pressure` endpoint- [ ] Expose `/predict-forces` endpoint- [ ] Write API documentation (Swagger)**Physics Service Tasks (TASKS.md:36-40):**- [ ] Create FastAPI server for VLM and Panel computations- [ ] Add mesh validator (manifold check, size limits)- [ ] Implement Redis cache for repeated meshes (LRU policy)- [ ] Expose `/vlm-solve` endpoint- [ ] Expose `/panel-solve` endpoint**Deliverable:**- ML inference service Docker container- Physics service Docker container- API documentation**Owner:** Backend Team**Status:** Pending**Dependency:** M1.3 (need trained model - can use dummy model initially)---##### Week 5: Quantum Optimization Service**Milestone M2.2: Quantum Service Operational****Tasks (TASKS.md:43-47):**- [ ] Build QUBO model generator from design variables- [ ] Implement QAOA pipeline with Qiskit- [ ] Add Aer simulator backend configuration- [ ] Implement warm-start initialization from ML predictions- [ ] Expose `/optimize` endpoint- [ ] Add classical fallback (SciPy COBYLA) if quantum fails- [ ] Write quantum service documentation**Deliverable:**- Quantum optimization service Docker container- QUBO encoding library- Quantum-classical hybrid loop**Owner:** Quantum Team**Status:** Pending**Blocker:** None (can develop independently)---##### Week 6: Backend Orchestration**Milestone M2.3: Backend Orchestration Functional****Tasks (TASKS.md:49-54):**- [ ] Build REST/GraphQL hybrid API with Apollo Server- [ ] Implement job orchestration logic (Bull queue)- [ ] Connect MongoDB with Mongoose schemas- [ ] Implement JWT authentication with refresh tokens- [ ] Add role-based access control (admin, engineer, viewer)- [ ] Implement service health checks- [ ] Set up NGINX reverse proxy**Deliverable:**- Backend API server Docker container- MongoDB schemas- Authentication system- NGINX configuration**Owner:** Backend Team**Status:** Pending**Dependency:** M2.1, M2.2 (need service endpoints)---#### Phase 3: GPU Surrogate Model Training (Weeks 7-10)**Goal:** Train high-accuracy surrogate model on GPU**Reference:** Quantum-Aero F1 Prototype PLAN.md:56-60, TASKS.md:59-75##### Week 7-8: Data Pipeline & Training**Milestone M3.1: Model Training Complete****Tasks (TASKS.md:61-63, 66-69):**- [ ] Build mesh ÔåÆ structured tensor conversion pipeline- [ ] Extract target variables from CFD simulations (pressure, forces)- [ ] Implement CUDA training loop with mixed precision (FP16/FP32)- [ ] Build checkpoint manager with automatic saving- [ ] Implement hyperparameter search (learning rate, batch size, architecture)- [ ] Train baseline model (target: <10% error on validation set)**Training Configuration:**```yamlmodel: GeoConvNetlayers: 6hidden_dim: 256batch_size: 16learning_rate: 1e-4optimizer: AdamWepochs: 100device: cudamixed_precision: truecheckpoint_freq: 5```**Deliverable:**- Trained PyTorch model- Training logs and metrics- Validation report (<10% error target)**Owner:** ML Team**Status:** Pending**Dependency:** M1.2 (dataset ready)---##### Week 9-10: ONNX Export & Optimization**Milestone M3.2: Production Model Deployed****Tasks (TASKS.md:72-74):**- [ ] Export PyTorch model to ONNX format- [ ] Validate ONNX model accuracy (must match PyTorch within 0.1%)- [ ] Test inference latency on RTX 4070 (target: <100ms)- [ ] Optimize ONNX graph (constant folding, operator fusion)- [ ] Quantize model to FP16 if latency target not met- [ ] Deploy to ML inference service- [ ] Run production load tests**Performance Targets:**- Inference time: <100ms (RTX 4070)- Accuracy: <5% error vs. CFD- Throughput: 10+ inferences/second**Deliverable:**- Production-ready ONNX model- Performance benchmark report- Deployed ML service**Owner:** ML Team**Status:** Pending**Dependency:** M3.1---#### Phase 4: Quantum Integration (Weeks 11-13)**Goal:** Integrate quantum optimization with full pipeline**Reference:** Quantum-Aero F1 Prototype PLAN.md:62-66, TASKS.md:78-93##### Week 11-12: QUBO Modeling & QAOA**Milestone M4.1: Quantum Optimization Integrated****Tasks (TASKS.md:80-83, 86-88):**- [ ] Define multi-objective optimization problem- [ ] Encode aerodynamic constraints as QUBO penalties- [ ] Implement QAOA mixer operators- [ ] Add classical optimizer (COBYLA) for variational parameters- [ ] Implement classical fallback mode (SciPy minimization)- [ ] Test on simplified 10-qubit problem- [ ] Benchmark convergence speed (<10 iterations target)**QUBO Formulation:**```python# Multi-objective QUBOH = ╬▒┬Àdrag - ╬▓┬Àdownforce + ╬│┬Àflutter_penalty + ╬┤┬Àmass_penalty# Binary encoding of design variablesthickness_i = ╬ú_k b_i_k ┬À thickness_levels[k]  # One-hot encodingstiffener_i = s_i Ôêê {0, 1}                      # Binary placement```**Deliverable:**- QUBO encoder library- QAOA optimizer- Classical fallback implementation- Benchmark results**Owner:** Quantum Team**Status:** Pending**Dependency:** M2.2---##### Week 13: End-to-End Testing**Milestone M4.2: Full Pipeline Validated****Tasks (TASKS.md:91-93):**- [ ] Run end-to-end optimization workflow- [ ] Validate quantum-optimized designs with physics service- [ ] Compare quantum vs. classical optimization results- [ ] Measure total optimization time (target: <30 minutes)- [ ] Verify constraint satisfaction (flutter, mass, stress)- [ ] Document performance comparison**Test Scenario:**```Input: Baseline F1 wing geometryObjective: Maximize L/D ratio while maintaining flutter marginConstraints:  - Flutter speed > 1.2 ├ù Vmax  - Mass < 5kg  - Max stress < ¤â_yield / 1.5Expected Output:  - Optimized geometry with 3-5% L/D improvement  - Flutter margin validated  - Quantum convergence in <10 iterations```**Deliverable:**- End-to-end test report- Performance comparison (quantum vs. classical)- Integration validation**Owner:** Integration Team**Status:** Pending**Dependency:** M3.2, M4.1---#### Phase 5: Front-End Development (Weeks 14-19)**Goal:** Build interactive 3D visualization and dashboards**Reference:** Quantum-Aero F1 Prototype PLAN.md:68-72, TASKS.md:97-113##### Week 14-15: UI Foundation**Milestone M5.1: UI Framework Operational****Tasks (TASKS.md:99-101):**- [ ] Set up Next.js 14 project with TypeScript- [ ] Implement dark-mode theme with TailwindCSS- [ ] Create landing page with project overview- [ ] Build navigation and routing structure- [ ] Implement authentication flow (login, register, logout)- [ ] Add protected routes for authenticated users**Deliverable:**- Next.js application skeleton- Dark-mode theme- Authentication flow**Owner:** Frontend Team**Status:** Pending**Blocker:** None (can develop in parallel)---##### Week 16-17: 3D Visualization**Milestone M5.2: 3D Viewer Functional****Tasks (TASKS.md:104-107):**- [ ] Build Three.js 3D viewer component- [ ] Integrate VTK.js for scientific field visualization- [ ] Add interactive camera controls (orbit, pan, zoom)- [ ] Implement mesh rendering with pressure colormap- [ ] Add vorticity field visualization (isosurfaces, streamlines)- [ ] Implement animation timeline for transient results- [ ] Add screenshot/video export functionality**Deliverable:**- 3D viewer component- Field visualization library- Interactive controls**Owner:** Frontend Team**Status:** Pending**Dependency:** M2.1 (need API for data)---##### Week 18-19: Dashboards & Analytics**Milestone M5.3: Dashboards Complete****Tasks (TASKS.md:110-113):**- [ ] Build real-time KPI dashboard (Cl, Cd, L/D, flutter margin)- [ ] Create job history table with filtering and sorting- [ ] Add performance charts (Recharts) for optimization convergence- [ ] Build comparison view for multiple designs- [ ] Implement parameter controls with sliders and inputs- [ ] Add validation feedback for user inputs**Deliverable:**- Dashboard components- KPI visualization- Job management UI**Owner:** Frontend Team**Status:** Pending**Dependency:** M2.3 (backend API)---#### Phase 6: Integration & Demo (Weeks 20-22)**Goal:** Final integration, testing, and demo preparation**Reference:** Quantum-Aero F1 Prototype PLAN.md:74-78, TASKS.md:116-142##### Week 20-21: System Integration**Milestone M6.1: Full System Integrated****Tasks (TASKS.md:119-121):**- [ ] Connect all microservices via docker-compose- [ ] Resolve latency bottlenecks (profiling, optimization)- [ ] Implement distributed tracing (Jaeger)- [ ] Set up centralized logging (ELK stack)- [ ] Configure Prometheus + Grafana monitoring- [ ] Optimize database queries and indexing- [ ] Implement API rate limiting**Deliverable:**- Integrated docker-compose stack- Monitoring dashboard- Performance optimization report**Owner:** Integration Team**Status:** Pending**Dependency:** M5.3---##### Week 22: Testing & Demo**Milestone M6.2: Production-Ready System****Tasks (TASKS.md:124-132):**- [ ] Run load tests (100+ concurrent users)- [ ] Run GPU stress tests (sustained load)- [ ] Execute security vulnerability scan- [ ] Prepare example simulations for F1 demo- [ ] Record walkthrough video (15-minute presentation)- [ ] Write deployment guide- [ ] Conduct final system validation**Demo Package Contents:**- [ ] Recorded video walkthrough- [ ] 5+ example F1 wing optimizations- [ ] Performance benchmark results- [ ] Deployment documentation- [ ] User manual**Deliverable:**- F1 team demo package- Production deployment- Final documentation**Owner:** Project Lead**Status:** Pending**Dependency:** M6.1---### Task Dependencies```mermaidgantt    title Project Timeline with Dependencies    dateFormat YYYY-MM-DD    section Phase 1    Environment Setup           :m1_1, 2026-01-01, 7d    Physics Engine             :m1_2, after m1_1, 7d    ML Architecture            :m1_3, after m1_2, 7d    section Phase 2    ML & Physics APIs          :m2_1, after m1_3, 7d    Quantum Service            :m2_2, after m1_1, 7d    Backend Orchestration      :m2_3, after m2_1 m2_2, 7d    section Phase 3    Model Training             :m3_1, after m1_2, 14d    ONNX Deployment            :m3_2, after m3_1, 14d    section Phase 4    QUBO & QAOA                :m4_1, after m2_2, 14d    End-to-End Testing         :m4_2, after m3_2 m4_1, 7d    section Phase 5    UI Foundation              :m5_1, after m2_3, 14d    3D Visualization           :m5_2, after m5_1, 14d    Dashboards                 :m5_3, after m5_2, 14d    section Phase 6    System Integration         :m6_1, after m5_3, 14d    Testing & Demo             :m6_2, after m6_1, 7d```---### Critical Path Analysis**Critical Path:** M1.1 ÔåÆ M1.2 ÔåÆ M1.3 ÔåÆ M3.1 ÔåÆ M3.2 ÔåÆ M4.2 ÔåÆ M6.1 ÔåÆ M6.2**Duration:** 22 weeks**Slack Analysis:**| Task | Slack Time | Can Delay Without Impact ||------|-----------|-------------------------|| M2.2 (Quantum Service) | +3 weeks | Yes (no dependency until M4.1) || M5.1 (UI Foundation) | +8 weeks | Yes (can start late, parallel work) || M2.1 (ML API) | 0 weeks | No (on critical path) || M3.1 (Training) | 0 weeks | No (on critical path) |**Parallelization Opportunities:**1. **Quantum service (M2.2)** can be developed fully in parallel with ML training (M3.1)2. **Frontend (M5.1-M5.3)** can start once backend API is stable (M2.3)3. **Documentation** can be written continuously throughout all phases---### Resource Allocation#### Team Structure**Proposed Team:**| Role | Count | Responsibilities | Phases ||------|-------|-----------------|--------|| **Project Lead** | 1 | Overall coordination, stakeholder communication | All || **ML Engineer** | 2 | Surrogate model training, ONNX optimization | 1, 3, 4 || **Physics Engineer** | 1 | VLM/Panel solver, aeroelastic analysis | 1, 4 || **Quantum Engineer** | 1 | QAOA implementation, QUBO formulation | 2, 4 || **Backend Developer** | 2 | Microservices, orchestration, database | 2, 6 || **Frontend Developer** | 2 | React UI, Three.js visualization | 5 || **DevOps Engineer** | 1 | Docker, CI/CD, monitoring | 1, 6 || **QA Engineer** | 1 | Testing, validation, quality assurance | 4, 6 |**Total:** 11 people---#### Hardware Allocation| Resource | Quantity | Assignment | Usage ||----------|----------|------------|-------|| **RTX 4090** | 1 | ML training | Phase 3 (100% utilization) || **RTX 4070** | 2 | ML inference service | Phases 2-6 (on-demand) || **CPU Server (32 cores)** | 1 | Physics service, FSI | Phases 1, 4, 6 || **Dev Workstations** | 11 | Development | All phases |---## Complex Components Handling### Complex Component Identification**Source:** Quantum-Aero F1 Prototype COMPLEX TRANSIENT.md (entire document)#### CC-1: Transient Aeroelastic FSI**Complexity Drivers:**- Multi-physics coupling (fluid + structure)- Nonlinear geometry effects- Time-dependent boundary conditions- Computationally expensive (6-24 hours per case)**Risk Level:** HIGH**Mitigation Strategy:**1. **Multi-Fidelity Approach** - Use ROM surrogates for exploration, FSI for validation only2. **Modal Reduction** - Project structural response onto 5-10 dominant modes3. **Parallel Execution** - Run multiple FSI cases concurrently on CPU cluster4. **Early Validation** - Start with simplified 2D cases before 3D**Reference:** Quantum-Aero F1 Prototype COMPLEX TRANSIENT.md:191-226**Implementation Timeline:** Phase 4 (weeks 11-13)---#### CC-2: Quantum QUBO Encoding**Complexity Drivers:**- Combinatorial explosion of design space (2^N configurations)- Constraint satisfaction in QUBO form (quadratic penalties)- Quantum circuit depth limitations (noise accumulation)- No guarantee of global optimum on NISQ hardware**Risk Level:** HIGH**Mitigation Strategy:**1. **Start Simple** - Begin with 10-qubit toy problems, gradually increase complexity2. **Warm-Start QAOA** - Initialize with classical ML-predicted solutions3. **Classical Fallback** - Always have SciPy optimizer as backup4. **Error Mitigation** - Implement zero-noise extrapolation (ZNE)5. **Hybrid Approach** - Use quantum for discrete variables, classical for continuous**Reference:** Quantum-Aero F1 Prototype AEROELASTIC.md:541-650**Implementation Timeline:** Phase 4 (weeks 11-12)---#### CC-3: GPU Surrogate Model Training**Complexity Drivers:**- High-dimensional input (10K+ mesh vertices)- Physics-informed loss function (continuity + momentum)- Data scarcity (expensive CFD simulations)- Generalization to unseen geometries**Risk Level:** MEDIUM**Mitigation Strategy:**1. **Data Augmentation** - Rotation, scaling, noise injection to expand dataset2. **Transfer Learning** - Pre-train on simpler 2D airfoils, fine-tune on 3D wings3. **Active Learning** - Intelligently select next CFD simulation to run4. **Physics-Informed Loss** - Enforce conservation laws in training loss5. **Ensemble Methods** - Train multiple models, use voting for predictions**Reference:** Genius_Evolution.md:40-109**Implementation Timeline:** Phase 3 (weeks 7-10)---#### CC-4: Real-Time 3D Visualization**Complexity Drivers:**- Large mesh rendering (100K+ triangles)- Real-time field updates (pressure, vorticity)- WebGL performance limitations- Cross-browser compatibility**Risk Level:** MEDIUM**Mitigation Strategy:**1. **Level of Detail (LOD)** - Use decimated meshes for far-away views2. **Progressive Loading** - Load low-res first, refine progressively3. **WebGL Optimization** - Use instanced rendering, frustum culling4. **Web Workers** - Offload data processing to background threads5. **Fallback Mode** - Static images if WebGL not supported**Reference:** Quantum-Aero F1 Prototype TASKS.md:104-107**Implementation Timeline:** Phase 5 (weeks 16-17)---### Risk Mitigation Strategies#### GPU Availability Risk**Probability:** MEDIUM**Impact:** HIGH**Risk Score:** HIGH**Mitigation:**1. **Cloud Fallback** - Use AWS/Azure GPU instances if local GPU fails2. **CPU Mode** - Implement CPU inference path (slower but functional)3. **Hardware Redundancy** - Have backup GPU available4. **Early Procurement** - Order hardware at project start**Reference:** Quantum-Aero F1 Prototype PLAN.md:94---#### Quantum Convergence Failure Risk**Probability:** MEDIUM**Impact:** MEDIUM**Risk Score:** MEDIUM**Mitigation:**1. **Classical Fallback** - Always have SciPy optimizer ready2. **Adaptive QAOA Depth** - Increase layers if not converging3. **Warm-Start** - Use ML predictions to initialize circuit4. **Hybrid Solver** - Mix quantum + classical approaches**Reference:** Quantum-Aero F1 Prototype DESIGN.md:54-58, PLAN.md:95---#### Data Quality Risk**Probability:** MEDIUM**Impact:** HIGH**Risk Score:** HIGH**Mitigation:**1. **Dataset Validation** - Verify all CFD results before training2. **Physical Consistency Checks** - Ensure conservation laws satisfied3. **Outlier Detection** - Remove anomalous simulations4. **Multiple Data Sources** - Use NASA + in-house CFD + literature**Reference:** Quantum-Aero F1 Prototype PLAN.md:96---#### Integration Complexity Risk**Probability:** HIGH**Impact:** HIGH**Risk Score:** CRITICAL**Mitigation:**1. **API Contracts Early** - Define interfaces before implementation2. **Contract Testing** - Use Pact for consumer-driven tests3. **Service Mocking** - Test each service independently4. **Integration Sprints** - Dedicate Phase 6 to integration5. **Continuous Integration** - Automated testing on every commit**Reference:** Quantum-Aero F1 Prototype PLAN.md:97---### Technical Debt Considerations#### Code Quality Standards- [ ] Linting: ESLint (JavaScript), Pylint (Python)- [ ] Formatting: Prettier (JavaScript), Black (Python)- [ ] Type Checking: TypeScript, MyPy- [ ] Code Coverage: >80% for critical paths- [ ] Documentation: Docstrings for all public functions---#### Refactoring Budget**Allocate 10% of development time for refactoring:**- Week 10: Refactor ML training pipeline- Week 15: Refactor backend orchestration- Week 20: Refactor frontend components---### Performance Optimization Approaches#### ML Inference Optimization**Baseline:** 200ms inference time (unoptimized)**Target:** <100ms**Optimization Techniques:**1. **ONNX Graph Optimization**   - Constant folding   - Operator fusion   - Dead code elimination2. **Mixed Precision (FP16)**   - 2x speedup on Tensor Cores   - Minimal accuracy loss3. **Batching**   - Batch size 8-16 for optimal GPU utilization4. **Model Pruning**   - Remove 30-50% of weights with minimal accuracy loss5. **Knowledge Distillation**   - Train smaller "student" model from large "teacher" model**Reference:** Quantum-Aero F1 Prototype DESIGN.md:40-44---#### Physics Solver Optimization**Baseline:** 60s VLM solve time**Target:** <10s**Optimization Techniques:**1. **Adaptive Mesh Refinement**   - Fine mesh only where needed (wake, boundary layer)2. **Fast Multipole Method**   - O(N log N) instead of O(N┬▓) for far-field3. **GPU Acceleration**   - Port matrix operations to CUDA4. **Precomputed Influence Matrices**   - Cache and reuse for similar geometries5. **Parallel Solve**   - Multi-threaded linear solver (OpenMP)**Reference:** Quantum-Aero F1 Prototype DESIGN.md:47-51---## Implementation Guidelines### Coding Standards and Conventions#### Python (Backend Microservices)**Style Guide:** PEP 8**Enforced with:**- Black (auto-formatter)- Pylint (linter)- MyPy (type checker)**Example:**```python# Good: Type hints, docstrings, descriptive namesdef compute_lift_coefficient(    pressure_field: np.ndarray,    surface_normals: np.ndarray,    reference_area: float,    dynamic_pressure: float) -> float:    """    Compute lift coefficient from pressure distribution.    Args:        pressure_field: Pressure values at surface points [Pa]        surface_normals: Surface normal vectors (normalized)        reference_area: Wing reference area [m┬▓]        dynamic_pressure: Freestream dynamic pressure [Pa]    Returns:        Lift coefficient (dimensionless)    Raises:        ValueError: If arrays have mismatched shapes    """    if pressure_field.shape[0] != surface_normals.shape[0]:        raise ValueError("Pressure and normals must have same length")    # Integrate pressure forces    lift_force = np.sum(pressure_field * surface_normals[:, 2])    cl = lift_force / (dynamic_pressure * reference_area)    return cl```---#### JavaScript/TypeScript (Frontend)**Style Guide:** Airbnb JavaScript Style Guide**Enforced with:**- ESLint- Prettier- TypeScript compiler**Example:**```typescript// Good: Interfaces, async/await, error handlinginterface AeroResult {  cl: number;  cd: number;  pressure: number[];  timestamp: Date;}async function fetchAeroResults(meshId: string): Promise<AeroResult> {  try {    const response = await fetch(`/api/v1/results/${meshId}`, {      headers: {        'Authorization': `Bearer ${getToken()}`,      },    });    if (!response.ok) {      throw new Error(`HTTP ${response.status}: ${response.statusText}`);    }    const data: AeroResult = await response.json();    return data;  } catch (error) {    console.error('Failed to fetch results:', error);    throw error;  }}```---### Testing Strategy#### Unit Testing**Framework:** Jest (JavaScript), pytest (Python)**Coverage Target:** >80% for critical paths**Example:**```python# test_aerodynamics.pyimport pytestfrom aerodynamics import compute_lift_coefficientdef test_lift_coefficient_positive():    """Lift coefficient should be positive for upward pressure."""    pressure = np.array([1000, 1100, 1200])  # Pa    normals = np.array([[0, 0, 1], [0, 0, 1], [0, 0, 1]])    area = 1.0  # m┬▓    q_inf = 1000  # Pa    cl = compute_lift_coefficient(pressure, normals, area, q_inf)    assert cl > 0, "Lift coefficient should be positive"    assert abs(cl - 3.3) < 0.1, "Expected Cl Ôëê 3.3"def test_lift_coefficient_mismatched_shapes():    """Should raise ValueError for mismatched array shapes."""    pressure = np.array([1000, 1100])    normals = np.array([[0, 0, 1]])  # Wrong size    with pytest.raises(ValueError, match="same length"):        compute_lift_coefficient(pressure, normals, 1.0, 1000)```---#### Integration Testing**Framework:** Supertest (API testing), pytest-docker**Strategy:**1. Spin up Docker containers for services2. Test API endpoints end-to-end3. Validate data flow across services4. Tear down containers**Example:**```javascript// test/integration/ml-service.test.jsconst request = require('supertest');const app = require('../src/app');describe('ML Inference Service', () => {  it('POST /api/v1/predict-pressure returns valid result', async () => {    const response = await request(app)      .post('/api/v1/predict-pressure')      .attach('mesh', './fixtures/naca0012.stl')      .field('velocity', '250')      .expect(200);    expect(response.body.success).toBe(true);    expect(response.body.data.pressure_field).toBeInstanceOf(Array);    expect(response.body.data.confidence).toBeGreaterThan(0.5);  });  it('POST /api/v1/predict-pressure rejects invalid mesh', async () => {    const response = await request(app)      .post('/api/v1/predict-pressure')      .attach('mesh', './fixtures/invalid.txt')      .expect(400);    expect(response.body.error.code).toBe(1001);  });});```---#### End-to-End Testing**Framework:** Playwright (browser testing)**Strategy:**1. User logs in2. Uploads mesh3. Runs optimization4. Views 3D visualization5. Verifies results**Example:**```javascript// e2e/optimization-workflow.spec.jsconst { test, expect } = require('@playwright/test');test('complete optimization workflow', async ({ page }) => {  // Login  await page.goto('http://localhost:3000/login');  await page.fill('input[name="email"]', 'test@example.com');  await page.fill('input[name="password"]', 'password123');  await page.click('button[type="submit"]');  // Upload mesh  await page.goto('http://localhost:3000/optimize');  await page.setInputFiles('input[type="file"]', './fixtures/wing.stl');  await page.fill('input[name="velocity"]', '250');  await page.click('button[type="submit"]');  // Wait for optimization to complete  await page.waitForSelector('.status-completed', { timeout: 60000 });  // Verify 3D visualization loads  await page.click('a[href="/results"]');  await page.waitForSelector('canvas');  // Check results  const cl = await page.textContent('.metric-cl');  expect(parseFloat(cl)).toBeGreaterThan(0);});```---### CI/CD Pipeline Requirements**Platform:** GitHub Actions**Pipeline Stages:**```yaml# .github/workflows/ci.ymlname: CI/CD Pipelineon:  push:    branches: [main, develop]  pull_request:    branches: [main]jobs:  lint:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v3      - name: Run ESLint        run: npm run lint      - name: Run Pylint        run: pylint **/*.py  unit-tests:    runs-on: ubuntu-latest    steps:      - uses: actions/checkout@v3      - name: Run Jest        run: npm test      - name: Run pytest        run: pytest --cov=src --cov-report=xml      - name: Upload coverage        uses: codecov/codecov-action@v3  integration-tests:    runs-on: ubuntu-latest    services:      mongodb:        image: mongo:7      redis:        image: redis:7    steps:      - uses: actions/checkout@v3      - name: Start services        run: docker-compose up -d      - name: Run integration tests        run: npm run test:integration  build-docker:    runs-on: ubuntu-latest    needs: [lint, unit-tests]    steps:      - uses: actions/checkout@v3      - name: Build images        run: docker-compose build      - name: Push to registry        run: docker-compose push  deploy:    runs-on: ubuntu-latest    needs: [build-docker, integration-tests]    if: github.ref == 'refs/heads/main'    steps:      - name: Deploy to production        run: ./scripts/deploy.sh```---### Documentation Standards#### API Documentation**Format:** OpenAPI 3.0 (Swagger)**Auto-generated from code annotations****Example:**```pythonfrom fastapi import FastAPIfrom pydantic import BaseModelapp = FastAPI(title="ML Inference Service", version="1.0.0")class PredictionRequest(BaseModel):    """Request model for pressure prediction."""    velocity: float = 250.0    yaw: float = 0.0    ride_height: float = 0.0class PredictionResponse(BaseModel):    """Response model with predicted pressure field."""    pressure_field: list[list[float]]    confidence: float@app.post("/api/v1/predict-pressure", response_model=PredictionResponse)async def predict_pressure(request: PredictionRequest):    """    Predict pressure distribution on uploaded mesh.    Args:        request: Prediction parameters    Returns:        Pressure field and confidence score    """    # Implementation    pass```**Generates Swagger UI at:** `http://localhost:8000/docs`---#### Code Documentation**Required for:**- All public functions and classes- Complex algorithms- Non-obvious implementation choices**Format:** Docstrings (Python), JSDoc (JavaScript)**Example:**```pythondef run_qaoa_optimization(    qubo_matrix: np.ndarray,    n_layers: int = 3,    max_iterations: int = 100,    warm_start: Optional[np.ndarray] = None) -> tuple[np.ndarray, float]:    """    Run QAOA optimization on QUBO problem.    This function implements the Quantum Approximate Optimization Algorithm    (QAOA) for solving binary quadratic optimization problems. It uses    Qiskit Aer simulator for circuit execution and SciPy COBYLA for    classical variational parameter optimization.    Args:        qubo_matrix: Symmetric QUBO matrix Q where energy = x^T Q x        n_layers: Number of QAOA layers (p parameter). Higher is more                  accurate but slower. Typical range: 1-5.        max_iterations: Maximum classical optimization iterations        warm_start: Optional initial bitstring to bias circuit initialization    Returns:        Tuple of (optimal_solution, optimal_energy)        - optimal_solution: Binary array of length n (qubit count)        - optimal_energy: Final QUBO energy (lower is better)    Raises:        ValueError: If QUBO matrix is not symmetric or max_iterations < 1    Example:        >>> Q = np.array([[0, -1], [-1, 0]])  # Simple 2-qubit problem        >>> solution, energy = run_qaoa_optimization(Q, n_layers=2)        >>> print(f"Solution: {solution}, Energy: {energy}")        Solution: [1 1], Energy: -2.0    References:        - Farhi et al. (2014). "A Quantum Approximate Optimization Algorithm"        - Qiskit QAOA tutorial: https://qiskit.org/textbook/ch-applications/qaoa    """    # Implementation    pass```---## Integration Checkpoints### Module Integration Sequence```mermaidflowchart TD    A[Phase 1: Foundation] --> B[Phase 2: Microservices]    B --> C[Checkpoint 1:<br/>Service APIs Validated]    C --> D[Phase 3: ML Training]    D --> E[Checkpoint 2:<br/>Surrogate Model Deployed]    E --> F[Phase 4: Quantum Integration]    F --> G[Checkpoint 3:<br/>End-to-End Optimization]    G --> H[Phase 5: Frontend]    H --> I[Checkpoint 4:<br/>UI Functional]    I --> J[Phase 6: Integration]    J --> K[Checkpoint 5:<br/>Production Ready]    style C fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff    style E fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff    style G fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff    style I fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff    style K fill:#10b981,stroke:#059669,stroke-width:3px,color:#fff```---### Checkpoint 1: Service APIs Validated (Week 6)**Entry Criteria:**- [ ] All microservices (ML, Physics, Quantum, Backend) deployed in Docker- [ ] API documentation (Swagger) published for each service- [ ] MongoDB connected and schemas defined**Testing Gates:**| Test ID | Description | Acceptance Criteria | Status ||---------|-------------|---------------------|--------|| **TC-API-01** | ML service responds to /predict-pressure | 200 OK with valid JSON | Pending || **TC-API-02** | Physics service responds to /vlm-solve | 200 OK with forces | Pending || **TC-API-03** | Quantum service responds to /optimize | 200 OK with solution | Pending || **TC-API-04** | Backend orchestrates ML + Physics call | Sequential execution | Pending || **TC-API-05** | Authentication rejects invalid JWT | 401 Unauthorized | Pending |**Exit Criteria:**- [ ] All tests passing- [ ] API latency <500ms (P95)- [ ] No critical bugs**Sign-off:** Backend Lead, QA Engineer---### Checkpoint 2: Surrogate Model Deployed (Week 10)**Entry Criteria:**- [ ] ML model trained with <10% validation error- [ ] ONNX model exported and validated- [ ] Model deployed to ML inference service**Testing Gates:**| Test ID | Description | Acceptance Criteria | Status ||---------|-------------|---------------------|--------|| **TC-ML-01** | Inference time <100ms on RTX 4070 | 95th percentile <100ms | Pending || **TC-ML-02** | Prediction error <5% vs. CFD | Mean absolute error <5% | Pending || **TC-ML-03** | Batch inference handles 16 meshes | No memory overflow | Pending || **TC-ML-04** | Model returns confidence scores | Confidence in [0, 1] | Pending || **TC-ML-05** | Graceful degradation on OOM | Returns error, doesn't crash | Pending |**Exit Criteria:**- [ ] All performance targets met- [ ] Model accuracy validated on holdout set- [ ] Production load testing passed**Sign-off:** ML Lead, QA Engineer---### Checkpoint 3: End-to-End Optimization (Week 13)**Entry Criteria:**- [ ] ML surrogate deployed- [ ] Quantum optimizer functional- [ ] Physics validation available**Testing Gates:**| Test ID | Description | Acceptance Criteria | Status ||---------|-------------|---------------------|--------|| **TC-E2E-01** | Upload mesh ÔåÆ Optimize ÔåÆ Results | Complete workflow in <30min | Pending || **TC-E2E-02** | Quantum finds better design than random | >10% improvement | Pending || **TC-E2E-03** | Optimized design validated by physics | Physics confirms improvement | Pending || **TC-E2E-04** | Workflow fails gracefully on error | Error logged, user notified | Pending || **TC-E2E-05** | Results stored in MongoDB | Queryable by meshId | Pending |**Exit Criteria:**- [ ] Full optimization workflow functional- [ ] Quantum optimizer demonstrably better than random search- [ ] All services integrated via backend orchestration**Sign-off:** Integration Lead, Physics Lead, Quantum Lead---### Checkpoint 4: UI Functional (Week 19)**Entry Criteria:**- [ ] Frontend deployed and accessible- [ ] Backend API stable- [ ] Authentication working**Testing Gates:**| Test ID | Description | Acceptance Criteria | Status ||---------|-------------|---------------------|--------|| **TC-UI-01** | User can log in | Redirected to dashboard | Pending || **TC-UI-02** | User can upload mesh | File uploaded, job queued | Pending || **TC-UI-03** | 3D visualization renders mesh | Canvas displays geometry | Pending || **TC-UI-04** | Pressure colormap updates | Real-time field update | Pending || **TC-UI-05** | Dashboard shows real-time metrics | KPIs update every 1s | Pending |**Exit Criteria:**- [ ] All core user journeys functional- [ ] UI responsive (mobile/tablet/desktop)- [ ] No critical accessibility issues**Sign-off:** Frontend Lead, UX Designer, QA Engineer---### Checkpoint 5: Production Ready (Week 22)**Entry Criteria:**- [ ] All previous checkpoints passed- [ ] System integration complete- [ ] Load testing complete**Testing Gates:**| Test ID | Description | Acceptance Criteria | Status ||---------|-------------|---------------------|--------|| **TC-LOAD-01** | 100 concurrent users | No performance degradation | Pending || **TC-LOAD-02** | GPU stress test (sustained load) | No throttling, no crashes | Pending || **TC-SEC-01** | Security vulnerability scan | No critical/high severity issues | Pending || **TC-REL-01** | 24-hour stability test | 99% uptime, no crashes | Pending || **TC-DEPLOY-01** | Deployment from scratch | Complete in <30 minutes | Pending |**Exit Criteria:**- [ ] All production tests passing- [ ] Monitoring and alerting configured- [ ] Deployment documentation complete- [ ] Backup and recovery tested**Sign-off:** Project Lead, DevOps Lead, QA Lead---### Quality Assurance Checkpoints**Automated QA Gates (run on every commit):**```yaml# Quality gates enforced by CI/CDgates:  - name: Linting    tool: ESLint, Pylint    threshold: Zero errors  - name: Unit Test Coverage    tool: Jest, pytest    threshold: >80% coverage  - name: Build Success    tool: Docker Compose    threshold: All images build  - name: Security Scan    tool: Snyk    threshold: No critical vulnerabilities```---## Traceability Matrix### Requirements ÔåÆ Design ÔåÆ Implementation ÔåÆ Testing| Req ID | Requirement | Design Spec | Implementation | Test Case | Status ||--------|------------|-------------|----------------|-----------|--------|| **FR-1** | Aerodynamic Prediction | DESIGN.md:40-44 | Phase 1.3, Phase 3 | TC-ML-01, TC-ML-02 | Pending || **FR-2** | Physics Validation | DESIGN.md:47-51 | Phase 1.2 | TC-PHYS-01 | Pending || **FR-3** | Quantum Optimization | DESIGN.md:54-58 | Phase 4.1 | TC-QUANT-01 | Pending || **FR-4** | Aeroelastic Analysis | AEROELASTIC.md | Phase 4.3 | TC-FSI-01 | Pending || **FR-5** | 3D Visualization | DESIGN.md:26-30 | Phase 5.2 | TC-UI-01 | Pending || **FR-6** | Job Orchestration | DESIGN.md:33-37 | Phase 2.4 | TC-ORCH-01 | Pending || **FR-7** | Authentication | DESIGN.md:91 | Phase 2.4 | TC-AUTH-01 | Pending || **NFR-1** | Performance | DESIGN.md:97-102 | All phases | TC-LOAD-01 | Pending || **NFR-2** | Scalability | DESIGN.md:5-19 | Phase 2, Phase 6 | TC-LOAD-02 | Pending || **NFR-3** | Reliability | PLAN.md:92-97 | Phase 6 | TC-REL-01 | Pending || **NFR-4** | Security | DESIGN.md:89-93 | Phase 2.4, Phase 6 | TC-SEC-01 | Pending |---### Task ÔåÆ Component Mapping| Task ID | Task Description | Component | Owner | Phase | Status ||---------|-----------------|-----------|-------|-------|--------|| **T-1.1** | Setup dev environment | DevOps | DevOps Lead | 1 | In Progress || **T-1.2** | Acquire datasets | Data | Physics Team | 1 | Pending || **T-1.3** | Implement VLM solver | Physics Service | Physics Team | 1 | Pending || **T-1.4** | Define ML architecture | ML Service | ML Team | 1 | Pending || **T-2.1** | Build ML inference API | ML Service | Backend Team | 2 | Pending || **T-2.2** | Build physics API | Physics Service | Backend Team | 2 | Pending || **T-2.3** | Build quantum API | Quantum Service | Quantum Team | 2 | Pending || **T-2.4** | Build backend orchestration | Backend | Backend Team | 2 | Pending || **T-3.1** | Train surrogate model | ML Service | ML Team | 3 | Pending || **T-3.2** | Export ONNX model | ML Service | ML Team | 3 | Pending || **T-4.1** | Implement QUBO encoding | Quantum Service | Quantum Team | 4 | Pending || **T-4.2** | Implement QAOA | Quantum Service | Quantum Team | 4 | Pending || **T-4.3** | Aeroelastic FSI setup | Physics Service | Physics Team | 4 | Pending || **T-5.1** | Build UI foundation | Frontend | Frontend Team | 5 | Pending || **T-5.2** | Build 3D viewer | Frontend | Frontend Team | 5 | Pending || **T-5.3** | Build dashboards | Frontend | Frontend Team | 5 | Pending || **T-6.1** | System integration | All Services | Integration Team | 6 | Pending || **T-6.2** | Load testing | All Services | QA Team | 6 | Pending || **T-6.3** | Demo preparation | All Services | Project Lead | 6 | Pending |---### Completion Status Tracking```mermaidpie title Project Completion Status    "Completed" : 5    "In Progress" : 10    "Pending" : 85```**Completion Metrics:**| Phase | Total Tasks | Completed | In Progress | Pending | % Complete ||-------|------------|-----------|-------------|---------|-----------|| Phase 1 | 12 | 2 | 3 | 7 | 17% || Phase 2 | 18 | 0 | 0 | 18 | 0% || Phase 3 | 8 | 0 | 0 | 8 | 0% || Phase 4 | 12 | 0 | 0 | 12 | 0% || Phase 5 | 15 | 0 | 0 | 15 | 0% || Phase 6 | 10 | 0 | 0 | 10 | 0% || **Total** | **75** | **2** | **3** | **70** | **3%** |---## Development Workflow### VS Codespaces Setup**Codespace Configuration:** `.devcontainer/devcontainer.json````json{  "name": "Q-Aero Development",  "image": "mcr.microsoft.com/devcontainers/python:3.11",  "features": {    "ghcr.io/devcontainers/features/node:1": {      "version": "20"    },    "ghcr.io/devcontainers/features/docker-in-docker:2": {},    "ghcr.io/devcontainers/features/nvidia-cuda:1": {      "version": "11.8"    }  },  "customizations": {    "vscode": {      "extensions": [        "ms-python.python",        "ms-python.vscode-pylance",        "esbenp.prettier-vscode",        "dbaeumer.vscode-eslint",        "ms-azuretools.vscode-docker"      ]    }  },  "forwardPorts": [3000, 8000, 8001, 8002, 27017],  "postCreateCommand": "bash .devcontainer/post-create.sh"}```**Post-Create Script:** `.devcontainer/post-create.sh````bash#!/bin/bash# Install Python dependenciespip install -r requirements.txt# Install Node dependenciesnpm install# Start MongoDB and Redisdocker-compose up -d mongodb redis# Initialize databasepython scripts/init_db.pyecho "Development environment ready!"```---### IDE Integration Points#### Python Development**Recommended Extensions:**- Python (Microsoft)- Pylance (Microsoft)- Jupyter (Microsoft)- autoDocstring**Settings (`.vscode/settings.json`):**```json{  "python.linting.enabled": true,  "python.linting.pylintEnabled": true,  "python.formatting.provider": "black",  "python.testing.pytestEnabled": true,  "[python]": {    "editor.formatOnSave": true,    "editor.codeActionsOnSave": {      "source.organizeImports": true    }  }}```---#### JavaScript/TypeScript Development**Recommended Extensions:**- ESLint (Microsoft)- Prettier (Prettier)- JavaScript and TypeScript Nightly- GraphQL**Settings:**```json{  "eslint.enable": true,  "editor.formatOnSave": true,  "editor.defaultFormatter": "esbenp.prettier-vscode",  "[javascript]": {    "editor.defaultFormatter": "esbenp.prettier-vscode"  }}```---### Debugging Procedures#### Debugging ML Inference Service**Launch Configuration (`.vscode/launch.json`):**```json{  "version": "0.2.0",  "configurations": [    {      "name": "Debug ML Service",      "type": "python",      "request": "launch",      "module": "uvicorn",      "args": [        "services.ml_inference.main:app",        "--reload",        "--host", "0.0.0.0",        "--port", "8000"      ],      "env": {        "CUDA_VISIBLE_DEVICES": "0",        "MODEL_PATH": "./models/surrogate_v1.onnx"      },      "jinja": true    }  ]}```**Debugging Steps:**1. Set breakpoints in ML service code2. Start debug session (F5)3. Send test request via Postman or curl4. Inspect variables, step through code5. Verify ONNX inference results---#### Debugging React Frontend**Launch Configuration:**```json{  "name": "Debug Frontend",  "type": "chrome",  "request": "launch",  "url": "http://localhost:3000",  "webRoot": "${workspaceFolder}/frontend",  "sourceMapPathOverrides": {    "webpack:///./src/*": "${webRoot}/src/*"  }}```**Debugging Steps:**1. Start Next.js dev server: `npm run dev`2. Start Chrome debugger (F5)3. Set breakpoints in React components4. Interact with UI to trigger breakpoints5. Inspect React state and props---### Testing Procedures#### Running Unit Tests**Python:**```bash# Run all testspytest# Run with coveragepytest --cov=src --cov-report=html# Run specific test filepytest tests/test_aerodynamics.py# Run specific testpytest tests/test_aerodynamics.py::test_lift_coefficient_positive```**JavaScript:**```bash# Run all testsnpm test# Run with coveragenpm test -- --coverage# Run specific test filenpm test -- ml-service.test.js# Watch modenpm test -- --watch```---#### Running Integration Tests**Start services:**```bash# Start all servicesdocker-compose up -d# Wait for health checks./scripts/wait-for-services.sh# Run integration testsnpm run test:integration# Stop servicesdocker-compose down```---#### Running E2E Tests```bash# Start full stackdocker-compose up -d# Run Playwright testsnpx playwright test# Run with UInpx playwright test --ui# Run specific testnpx playwright test e2e/optimization-workflow.spec.js```---### Collaboration Protocols#### Git Workflow**Branch Strategy:** Git Flow```main (production)  Ôö£ÔöÇÔöÇ develop (integration)  Ôöé   Ôö£ÔöÇÔöÇ feature/ml-surrogate  Ôöé   Ôö£ÔöÇÔöÇ feature/quantum-optimization  Ôöé   Ôö£ÔöÇÔöÇ feature/3d-visualization  Ôöé   ÔööÔöÇÔöÇ bugfix/mesh-validation  ÔööÔöÇÔöÇ hotfix/critical-bug```**Commit Message Convention:**```<type>(<scope>): <subject><body><footer>```**Types:**- `feat`: New feature- `fix`: Bug fix- `docs`: Documentation- `style`: Code style (formatting)- `refactor`: Code refactoring- `test`: Adding tests- `chore`: Build/config changes**Example:**```feat(ml-service): add ONNX model inference endpointImplemented /api/v1/predict-pressure endpoint with ONNX Runtime GPU.Includes request validation, batching, and error handling.Closes #42```---#### Pull Request Process1. **Create Feature Branch**   ```bash   git checkout develop   git pull origin develop   git checkout -b feature/my-feature   ```2. **Make Changes & Commit**   ```bash   git add .   git commit -m "feat(scope): description"   ```3. **Push & Open PR**   ```bash   git push origin feature/my-feature   # Open PR on GitHub: feature/my-feature ÔåÆ develop   ```4. **Code Review**   - At least 1 approval required   - All CI checks must pass   - No merge conflicts5. **Merge**   - Squash and merge to keep history clean   - Delete feature branch after merge---#### Code Review Checklist**Reviewer Responsibilities:**- [ ] Code follows style guide- [ ] All tests passing- [ ] No security vulnerabilities- [ ] Performance considerations addressed- [ ] Documentation updated- [ ] No breaking changes (or properly versioned)- [ ] Error handling adequate- [ ] Edge cases covered---## Synthetic Data Generation & Visualization### OverviewSynthetic data generation is **critical** for training ML surrogate models and validating aerodynamic predictions. This section outlines frameworks, data sources, and visualization tools for generating and analyzing aerodynamic data for F1 components and airfoils.**Key Requirements:**- Generate 10,000+ CFD simulations for ML training- Access validated NACA/NASA airfoil data- Create synthetic geometries for design space exploration- Visualize steady-state and transient flow fields- Animate dynamic phenomena (DRS activation, corner exit)---### Synthetic Data Generation Frameworks#### Category 1: High-Fidelity CFD Simulation##### OpenFOAM (Open-Source CFD)**Description:** Industry-standard open-source CFD toolkit for complex fluid dynamics.**Use Cases:**- High-fidelity validation runs- Transient aerodynamics (DRS activation, corner exit)- Fluid-structure interaction (FSI) with preCICE**Key Capabilities:**- Incompressible/compressible solvers (simpleFoam, pimpleFoam)- Turbulence models (k-¤ë SST, LES, DES)- Dynamic mesh for moving boundaries- Parallel execution (MPI)**Installation (VS Codespaces):**```bash# Docker container with OpenFOAMdocker pull openfoam/openfoam10-paraview510# Or install in Ubuntusudo sh -c "wget -O - https://dl.openfoam.org/gpg.key | apt-key add -"sudo add-apt-repository http://dl.openfoam.org/ubuntusudo apt-get updatesudo apt-get install openfoam10```**Example Workflow:**```bash# 1. Create case directorymkdir -p cases/wing_casecd cases/wing_casecp -r $FOAM_TUTORIALS/incompressible/simpleFoam/airFoil2D/* .# 2. Preprocess meshblockMeshsnappyHexMesh -overwrite# 3. Set boundary conditions (edit 0/ directory)# velocity: 250 km/h = 69.4 m/s# pressure: atmospheric# 4. Run simulationsimpleFoam > log.simpleFoam &# 5. Post-processfoamToVTK  # Convert to VTK for ParaView```**Automation Script:**```python# generate_cfd_dataset.pyimport osimport subprocessfrom pathlib import Pathdef run_openfoam_batch(geometries, velocities, yaw_angles):    """Generate CFD dataset for multiple configurations."""    results = []    for geom_id, geom_file in enumerate(geometries):        for vel in velocities:            for yaw in yaw_angles:                case_name = f"case_{geom_id}_v{vel}_yaw{yaw}"                case_dir = Path("cases") / case_name                # Setup case                setup_case(case_dir, geom_file, vel, yaw)                # Run simulation                subprocess.run(                    ["simpleFoam"],                    cwd=case_dir,                    stdout=open(case_dir / "log.txt", "w")                )                # Extract results                forces = extract_forces(case_dir)                pressure = extract_pressure_field(case_dir)                results.append({                    "geometry": geom_id,                    "velocity": vel,                    "yaw": yaw,                    "Cl": forces["lift_coefficient"],                    "Cd": forces["drag_coefficient"],                    "pressure_field": pressure                })    return results# Run batchvelocities = [150, 180, 210, 240, 270, 300]  # km/hyaw_angles = [0, 2, 4, 6, 8, 10]  # degreesgeometries = load_geometry_library("data/wings/")dataset = run_openfoam_batch(geometries, velocities, yaw_angles)save_dataset(dataset, "data/training_set.h5")```**Performance:**- **Computation Time:** 6-24 hours per case (F1 full car)- **Resolution:** 1-10M cells typical- **Accuracy:** ┬▒2% vs. wind tunnel (validated)**Reference:** Quantum-Aero F1 Prototype COMPLEX TRANSIENT.md:193-201---##### SU2 (Stanford University Unstructured)**Description:** Open-source CFD/optimization suite optimized for aerodynamic design.**Use Cases:**- Shape optimization with adjoint methods- Compressible flow (high-speed scenarios)- Automated design sweeps**Key Capabilities:**- Automatic differentiation for gradients- Built-in optimization (gradient descent, genetic algorithms)- GPU acceleration support- Mesh adaptation**Installation:**```bash# Clone and buildgit clone https://github.com/su2code/SU2.gitcd SU2./meson.py build --prefix=/usr/local -Denable-autodiff=true./ninja -C build install```**Example Configuration:**```cfg% SU2 Configuration: NACA 0012 AirfoilSOLVER= RANSKIND_TURB_MODEL= SSTMACH_NUMBER= 0.2AOA= 5.0FREESTREAM_TEMPERATURE= 288.15REYNOLDS_NUMBER= 6.0E6MARKER_HEATFLUX= ( airfoil, 0.0 )MARKER_FAR= ( farfield )CONV_NUM_METHOD_FLOW= ROEMUSCL_FLOW= YESSLOPE_LIMITER_FLOW= VENKATAKRISHNANITER= 5000CONV_RESIDUAL_MINVAL= -12```**Optimization Example:**```python# su2_optimization.pyimport subprocessimport numpy as npdef run_su2_optimization(design_vars):    """    Optimize airfoil shape using SU2 adjoint solver.    Design variables: camber distribution (10 points)    Objective: Maximize L/D ratio    Constraints: Cl > 0.5, thickness > 0.12c    """    # Write design to FFD file    write_ffd_file(design_vars, "design.ffd")    # Run primal solution    subprocess.run(["SU2_CFD", "config.cfg"])    # Run adjoint for gradients    subprocess.run(["SU2_CFD_AD", "config.cfg"])    # Extract objective and gradients    obj = extract_objective("history.csv")    grad = extract_gradients("of_grad.dat")    return obj, grad# Gradient-based optimizationfrom scipy.optimize import minimizex0 = np.zeros(10)  # Initial designresult = minimize(    lambda x: -run_su2_optimization(x)[0],  # Maximize L/D    x0,    method='SLSQP',    jac=lambda x: -run_su2_optimization(x)[1],    options={'maxiter': 50})print(f"Optimized L/D: {-result.fun}")```**Reference:** Genius_Evolution.md:110-127---##### PyFR (GPU-Accelerated High-Order CFD)**Description:** High-order CFD solver optimized for GPU execution (NVIDIA/AMD).**Use Cases:**- Massively parallel simulations- GPU cluster utilization- High-order accuracy (spectral methods)**Key Capabilities:**- GPU acceleration (CUDA, OpenCL, HIP)- High-order DG/FR schemes- Unstructured meshes- Explicit time integration**Installation:**```bashpip install pyfr# Requires: CUDA Toolkit, cuBLAS, cuFFT```**Performance:**- **Speedup:** 10-50x faster than CPU-based OpenFOAM- **GPU Utilization:** 90%+ on RTX 4090- **Scalability:** Near-linear scaling to 1000+ GPUs**Example:**```python# Run PyFR on GPUpyfr run -b cuda -p mesh.pyfrm config.ini```---#### Category 2: Low-Fidelity Fast Methods##### XFOIL (2D Airfoil Analysis)**Description:** Panel method + boundary layer solver for 2D airfoils.**Use Cases:**- Rapid airfoil analysis (seconds per case)- NACA airfoil database generation- Preliminary design screening**Key Capabilities:**- Inviscid panel method- Integral boundary layer equations- Transition prediction (eN method)- Polar generation (Cl vs. ╬▒)**Installation:**```bashsudo apt-get install xfoil```**Python Wrapper:**```python# xfoil_wrapper.pyimport subprocessimport numpy as npdef analyze_airfoil(coordinates, reynolds, alpha_range):    """    Run XFOIL analysis on airfoil coordinates.    Args:        coordinates: Nx2 array of (x, y) points        reynolds: Reynolds number        alpha_range: [alpha_min, alpha_max, alpha_step]    Returns:        Dict with Cl, Cd, Cm vs. alpha    """    # Write coordinates to file    np.savetxt("airfoil.dat", coordinates)    # Generate XFOIL input script    with open("xfoil_script.txt", "w") as f:        f.write(f"""LOAD airfoil.datPANEOPERVISC {reynolds}PACCpolar.txtASEQ {alpha_range[0]} {alpha_range[1]} {alpha_range[2]}QUIT""")    # Run XFOIL    subprocess.run(["xfoil < xfoil_script.txt"], shell=True)    # Parse results    polar = np.loadtxt("polar.txt", skiprows=12)    return {        "alpha": polar[:, 0],        "Cl": polar[:, 1],        "Cd": polar[:, 2],        "Cm": polar[:, 4]    }# Example: NACA 4412coords = generate_naca_airfoil("4412", n_points=100)results = analyze_airfoil(coords, reynolds=6e6, alpha_range=[-5, 15, 0.5])import matplotlib.pyplot as pltplt.plot(results["alpha"], results["Cl"], label="Cl")plt.plot(results["alpha"], results["Cd"]*10, label="Cd ├ù 10")plt.xlabel("Angle of Attack (deg)")plt.ylabel("Coefficient")plt.legend()plt.grid()plt.savefig("polar.png")```**Data Generation:**```python# generate_naca_dataset.pydef generate_naca_dataset():    """Generate comprehensive NACA airfoil database."""    naca_codes = [        "0006", "0009", "0012", "0015", "0018",  # Symmetric        "2412", "2415", "4412", "4415", "6409",  # Cambered        "23012", "23015", "63-215", "64-210"     # Modern    ]    reynolds_numbers = [1e6, 3e6, 6e6, 9e6]    dataset = []    for naca in naca_codes:        coords = generate_naca_airfoil(naca)        for re in reynolds_numbers:            results = analyze_airfoil(coords, re, [-10, 20, 0.5])            dataset.append({                "naca": naca,                "reynolds": re,                "geometry": coords,                "polar": results            })    # Save as HDF5    import h5py    with h5py.File("naca_database.h5", "w") as f:        for i, data in enumerate(dataset):            grp = f.create_group(f"airfoil_{i}")            grp.attrs["naca"] = data["naca"]            grp.attrs["reynolds"] = data["reynolds"]            grp.create_dataset("geometry", data=data["geometry"])            grp.create_dataset("alpha", data=data["polar"]["alpha"])            grp.create_dataset("Cl", data=data["polar"]["Cl"])            grp.create_dataset("Cd", data=data["polar"]["Cd"])    print(f"Generated {len(dataset)} airfoil cases")    return dataset# Run generationdataset = generate_naca_dataset()```**Reference:** Quantum-Aero F1 Prototype TASKS.md:17---##### Vortex Lattice Method (VLM) - Custom Implementation**Description:** Potential flow method for 3D lifting surfaces.**Use Cases:**- Medium-fidelity validation (Phase 1.2)- Real-time optimization inner loop- Preliminary F1 wing analysis**Implementation:**```python# vlm_solver.pyimport numpy as npfrom scipy.linalg import solveclass VLMSolver:    """    Vortex Lattice Method solver for lifting surfaces.    References:        - Anderson, Fundamentals of Aerodynamics (Ch. 4)        - Katz & Plotkin, Low-Speed Aerodynamics (Ch. 12)    """    def __init__(self, surface_mesh, n_panels_chord=20, n_panels_span=40):        self.mesh = surface_mesh        self.nc = n_panels_chord        self.ns = n_panels_span        self.panels = self._discretize_surface()    def solve(self, velocity, alpha, beta=0):        """        Solve for circulation distribution.        Args:            velocity: Freestream velocity [m/s]            alpha: Angle of attack [degrees]            beta: Sideslip angle [degrees]        Returns:            Dict with forces, moments, pressure distribution        """        # Freestream velocity vector        alpha_rad = np.radians(alpha)        beta_rad = np.radians(beta)        V_inf = velocity * np.array([            np.cos(alpha_rad) * np.cos(beta_rad),            np.sin(beta_rad),            np.sin(alpha_rad) * np.cos(beta_rad)        ])        # Build influence matrix A        A = self._compute_influence_matrix()        # Right-hand side: boundary condition (flow tangency)        b = self._compute_rhs(V_inf)        # Solve for vortex strengths        gamma = solve(A, b)        # Compute forces        forces = self._compute_forces(gamma, V_inf)        # Compute pressure distribution        cp = self._compute_pressure_coefficient(gamma, velocity)        return {            "lift": forces["L"],            "drag": forces["D"],            "moment": forces["M"],            "Cl": forces["Cl"],            "Cd": forces["Cd"],            "Cm": forces["Cm"],            "circulation": gamma,            "cp_distribution": cp        }    def _compute_influence_matrix(self):        """Compute induced velocity influence coefficients."""        n = len(self.panels)        A = np.zeros((n, n))        for i, panel_i in enumerate(self.panels):            for j, panel_j in enumerate(self.panels):                # Biot-Savart law for horseshoe vortex                v_ind = self._horseshoe_vortex_influence(                    panel_j.vortex_line,                    panel_i.control_point                )                # Normal component                A[i, j] = np.dot(v_ind, panel_i.normal)        return A    def _horseshoe_vortex_influence(self, vortex_line, point):        """Biot-Savart law for horseshoe vortex."""        # Implement Biot-Savart integration        # (simplified for brevity)        pass    def _compute_forces(self, gamma, V_inf):        """Kutta-Joukowski theorem for force calculation."""        rho = 1.225  # Air density [kg/m┬│]        # Integrate circulation ├ù velocity        L = 0        D = 0        M = np.zeros(3)        for panel, g in zip(self.panels, gamma):            dL = rho * g * panel.area * np.linalg.norm(V_inf)            L += dL            # Induced drag from downwash (Trefftz plane)            # (simplified)        # Non-dimensionalize        q_inf = 0.5 * rho * np.linalg.norm(V_inf)**2        S_ref = self._reference_area()        Cl = L / (q_inf * S_ref)        Cd = D / (q_inf * S_ref)        return {"L": L, "D": D, "M": M, "Cl": Cl, "Cd": Cd, "Cm": 0}# Example usagewing_mesh = load_mesh("data/f1_wing.stl")vlm = VLMSolver(wing_mesh, n_panels_chord=20, n_panels_span=40)results = vlm.solve(velocity=250/3.6, alpha=5)  # 250 km/h, 5┬░ AoAprint(f"Cl = {results['Cl']:.3f}, Cd = {results['Cd']:.4f}")```**Performance:**- **Computation Time:** 1-10 seconds per case- **Accuracy:** ┬▒10% vs. RANS for attached flow- **Use Case:** 1000s of evaluations for optimization**Reference:** Quantum-Aero F1 Prototype DESIGN.md:47-51---#### Category 3: ML-Based Synthetic Generation##### Generative Adversarial Networks (GANs) for Geometry**Description:** Neural networks that generate novel aerodynamic shapes.**Use Cases:**- Design space exploration- Discovering non-intuitive geometries- Augmenting limited training data**Architecture:**```python# aero_gan.pyimport torchimport torch.nn as nnclass AeroGAN:    """    GAN for generating F1 wing cross-sections.    Generator: latent vector (128D) ÔåÆ wing geometry (256 points)    Discriminator: wing geometry ÔåÆ real/fake probability    """    def __init__(self):        self.generator = Generator(latent_dim=128, output_dim=512)        self.discriminator = Discriminator(input_dim=512)        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")    def train(self, real_geometries, epochs=1000):        """Train GAN on real F1 wing geometries."""        optimizer_G = torch.optim.Adam(self.generator.parameters(), lr=0.0002)        optimizer_D = torch.optim.Adam(self.discriminator.parameters(), lr=0.0002)        criterion = nn.BCELoss()        for epoch in range(epochs):            # Train Discriminator            real_data = real_geometries[torch.randint(0, len(real_geometries), (64,))]            real_labels = torch.ones(64, 1)            z = torch.randn(64, 128)  # Latent noise            fake_data = self.generator(z)            fake_labels = torch.zeros(64, 1)            loss_D_real = criterion(self.discriminator(real_data), real_labels)            loss_D_fake = criterion(self.discriminator(fake_data.detach()), fake_labels)            loss_D = loss_D_real + loss_D_fake            optimizer_D.zero_grad()            loss_D.backward()            optimizer_D.step()            # Train Generator            z = torch.randn(64, 128)            fake_data = self.generator(z)            loss_G = criterion(self.discriminator(fake_data), real_labels)            optimizer_G.zero_grad()            loss_G.backward()            optimizer_G.step()            if epoch % 100 == 0:                print(f"Epoch {epoch}: D loss = {loss_D:.4f}, G loss = {loss_G:.4f}")    def generate(self, n_samples=100):        """Generate novel wing geometries."""        z = torch.randn(n_samples, 128)        with torch.no_grad():            geometries = self.generator(z).cpu().numpy()        return geometriesclass Generator(nn.Module):    def __init__(self, latent_dim, output_dim):        super().__init__()        self.model = nn.Sequential(            nn.Linear(latent_dim, 256),            nn.ReLU(),            nn.Linear(256, 512),            nn.ReLU(),            nn.Linear(512, output_dim),            nn.Tanh()  # Output in [-1, 1]        )    def forward(self, z):        return self.model(z)class Discriminator(nn.Module):    def __init__(self, input_dim):        super().__init__()        self.model = nn.Sequential(            nn.Linear(input_dim, 512),            nn.LeakyReLU(0.2),            nn.Linear(512, 256),            nn.LeakyReLU(0.2),            nn.Linear(256, 1),            nn.Sigmoid()        )    def forward(self, x):        return self.model(x)# Usagegan = AeroGAN()real_wings = load_f1_wing_database("data/wings/")gan.train(real_wings, epochs=5000)# Generate 1000 novel designssynthetic_wings = gan.generate(n_samples=1000)save_geometries(synthetic_wings, "data/synthetic_wings.h5")```**Reference:** Genius_Evolution.md:68-79---##### Physics-Informed Neural Networks (PINNs)**Description:** Neural networks that enforce physical laws (Navier-Stokes) as soft constraints.**Use Cases:**- Generate flow fields satisfying conservation laws- Interpolate between sparse CFD simulations- Reconstruct full fields from sensor data**Implementation:**```python# pinn_flow_generator.pyimport torchimport torch.nn as nnclass FlowFieldPINN(nn.Module):    """    Physics-Informed Neural Network for flow field generation.    Input: (x, y, z) spatial coordinates    Output: (u, v, w, p) velocity components and pressure    Loss = Data loss + Physics loss (Navier-Stokes residual)    """    def __init__(self):        super().__init__()        self.network = nn.Sequential(            nn.Linear(3, 128),            nn.Tanh(),            nn.Linear(128, 128),            nn.Tanh(),            nn.Linear(128, 128),            nn.Tanh(),            nn.Linear(128, 4)  # u, v, w, p        )    def forward(self, coords):        """Predict flow field at given coordinates."""        return self.network(coords)    def physics_loss(self, coords):        """Compute Navier-Stokes residual."""        coords.requires_grad_(True)        # Forward pass        flow = self.forward(coords)        u, v, w, p = flow[:, 0], flow[:, 1], flow[:, 2], flow[:, 3]        # Compute gradients        grad_u = torch.autograd.grad(u, coords, torch.ones_like(u), create_graph=True)[0]        grad_v = torch.autograd.grad(v, coords, torch.ones_like(v), create_graph=True)[0]        grad_w = torch.autograd.grad(w, coords, torch.ones_like(w), create_graph=True)[0]        grad_p = torch.autograd.grad(p, coords, torch.ones_like(p), create_graph=True)[0]        # Continuity equation: Ôêç┬Àv = 0        continuity = grad_u[:, 0] + grad_v[:, 1] + grad_w[:, 2]        # Momentum equation (simplified, inviscid)        # ¤ü(v┬ÀÔêç)v + Ôêçp = 0        momentum_x = (u * grad_u[:, 0] + v * grad_u[:, 1] + w * grad_u[:, 2]) + grad_p[:, 0]        momentum_y = (u * grad_v[:, 0] + v * grad_v[:, 1] + w * grad_v[:, 2]) + grad_p[:, 1]        momentum_z = (u * grad_w[:, 0] + v * grad_w[:, 1] + w * grad_w[:, 2]) + grad_p[:, 2]        # Total physics loss        loss = torch.mean(continuity**2 + momentum_x**2 + momentum_y**2 + momentum_z**2)        return loss    def train_pinn(self, sparse_cfd_data, epochs=10000):        """Train PINN on sparse CFD simulations."""        optimizer = torch.optim.Adam(self.parameters(), lr=1e-4)        for epoch in range(epochs):            # Data loss (match sparse CFD points)            coords_data = sparse_cfd_data["coords"]            flow_data = sparse_cfd_data["flow"]            flow_pred = self.forward(coords_data)            loss_data = torch.mean((flow_pred - flow_data)**2)            # Physics loss (enforce PDE everywhere)            coords_physics = torch.rand(1000, 3) * 10  # Random points in domain            loss_physics = self.physics_loss(coords_physics)            # Total loss            loss = loss_data + 0.01 * loss_physics            optimizer.zero_grad()            loss.backward()            optimizer.step()            if epoch % 1000 == 0:                print(f"Epoch {epoch}: Data loss = {loss_data:.6f}, Physics loss = {loss_physics:.6f}")# Usagepinn = FlowFieldPINN()# Load sparse CFD data (e.g., 100 simulations with 10K points each)sparse_data = load_sparse_cfd("data/sparse_cfd.h5")# Train PINNpinn.train_pinn(sparse_data, epochs=10000)# Generate dense flow field (1M points)dense_coords = generate_dense_mesh(n_points=1000000)dense_flow = pinn(dense_coords)save_flow_field(dense_coords, dense_flow, "data/dense_flow_field.h5")```**Reference:** Genius_Evolution.md:58-66---### Real Data Sources#### NASA Databases##### 1. NASA Turbulence Modeling Resource**URL:** https://turbmodels.larc.nasa.gov/**Content:**- Validation cases for turbulence models- 2D and 3D flow benchmarks- Experimental data for comparison**Key Datasets:**- NACA 0012 airfoil (subsonic/transonic)- RAE 2822 airfoil (transonic)- NASA Trap Wing (high-lift configuration)- NASA Juncture Flow Model**Download Example:**```bash# Download NACA 0012 validation casewget https://turbmodels.larc.nasa.gov/NACA0012_val/n0012_val.tar.gztar -xzf n0012_val.tar.gz# Contains:# - Experimental Cp data# - Grid files (PLOT3D format)# - Reference solutions```---##### 2. NASA CFD Vision 2030 Database**URL:** https://www.nas.nasa.gov/publications/software/docs/cfdvision2030/**Content:**- High-fidelity LES/DNS data- Complex configurations- Validation datasets for ML**Key Datasets:**- High-lift configuration (HL-CRM)- Swept wing in crossflow- Jet-in-crossflow---##### 3. NASA Airfoil Database**URL:** https://www.grc.nasa.gov/WWW/K-12/airplane/airfoil.html**Content:**- Historical NACA airfoil data- Pressure distributions- Lift/drag polars**Downloadable Formats:**- Text files (.txt)- Excel spreadsheets (.xls)---#### UIUC Airfoil Database**URL:** https://m-selig.ae.illinois.edu/ads/coord_database.html**Content:**- 1,600+ airfoil coordinate files- NACA, NASA, modern airfoils- Public domain**Download Script:**```python# download_uiuc_airfoils.pyimport requestsfrom bs4 import BeautifulSoupimport osdef download_uiuc_database():    """Download entire UIUC airfoil coordinate database."""    base_url = "https://m-selig.ae.illinois.edu/ads/"    coord_url = base_url + "coord_database.html"    # Parse index page    response = requests.get(coord_url)    soup = BeautifulSoup(response.text, 'html.parser')    # Find all airfoil links    links = soup.find_all('a', href=lambda x: x and x.endswith('.dat'))    os.makedirs("data/uiuc_airfoils", exist_ok=True)    for link in links:        filename = link['href']        airfoil_name = filename.replace('.dat', '')        # Download coordinate file        dat_url = base_url + filename        dat_response = requests.get(dat_url)        # Save to file        with open(f"data/uiuc_airfoils/{filename}", "w") as f:            f.write(dat_response.text)        print(f"Downloaded: {airfoil_name}")    print(f"Total airfoils downloaded: {len(links)}")# Run downloaddownload_uiuc_database()```---#### OpenFOAM Tutorial Cases**Location:** `$FOAM_TUTORIALS` (after OpenFOAM installation)**Key Cases:**- `incompressible/simpleFoam/airFoil2D` - 2D airfoil- `incompressible/pimpleFoam/wingMotion` - Pitching wing- `incompressible/simpleFoam/motorBike` - Complex geometry**Export to Dataset:**```python# export_openfoam_tutorials.pyimport osimport subprocessfrom pathlib import Pathdef export_tutorial_to_hdf5(tutorial_path):    """Convert OpenFOAM tutorial results to HDF5."""    # Run case if not already run    if not (tutorial_path / "postProcessing").exists():        subprocess.run(["./Allrun"], cwd=tutorial_path)    # Convert to VTK    subprocess.run(["foamToVTK"], cwd=tutorial_path)    # Parse VTK files to HDF5    vtk_dir = tutorial_path / "VTK"    # (VTK parsing code here)# Export all airfoil casesfoam_tutorials = Path(os.environ["FOAM_TUTORIALS"])airfoil_cases = foam_tutorials.glob("**/airFoil*")for case in airfoil_cases:    export_tutorial_to_hdf5(case)```---#### F1 Technical Databases##### F1 Technical Analysis Archive**URL:** https://www.f1technical.net/**Content:**- Historical F1 car specifications- Aerodynamic development articles- Wing geometry photos (for reference)**Note:** Most F1 CAD data is proprietary. Use simplified/parameterized models.---##### Simplified F1 Models**Open-Source Repositories:**```bash# Clone F1 open-source modelsgit clone https://github.com/Formula-One-CAD/F1-2022-Models.git# Contains:# - Simplified wing geometries (STL)# - Floor models# - Diffuser shapes```---### Visualization Tools#### Category 1: Open-Source Scientific Visualization##### ParaView (Recommended)**Description:** Industry-standard open-source visualization for CFD/FEA.**Installation:**```bash# Ubuntusudo apt-get install paraview# Or download from: https://www.paraview.org/download/```**Key Features:**- **Volume Rendering:** Visualize 3D scalar fields (pressure, vorticity)- **Streamlines:** Trace particle paths through flow field- **Isosurfaces:** Render surfaces of constant value (Q-criterion for vortices)- **Glyphs:** Vector field visualization (velocity arrows)- **Animation:** Time-series playback for transient simulations- **Python Scripting:** Automate visualization workflows**Example Workflow:**```python# paraview_automation.pyfrom paraview.simple import *# Load VTK filereader = OpenDataFile("cases/wing_case/VTK/wing_case.vtk")# Create slice through center planeslice = Slice(Input=reader)slice.SliceType = 'Plane'slice.SliceType.Origin = [0, 0, 0]slice.SliceType.Normal = [0, 1, 0]  # Y-normal (spanwise slice)# Color by pressurepressureDisplay = Show(slice)pressureDisplay.Representation = 'Surface'pressureDisplay.ColorArrayName = ['POINTS', 'p']# Set colormappressureLUT = GetColorTransferFunction('p')pressureLUT.ApplyPreset('Cool to Warm', True)# Add streamlinesstreamTracer = StreamTracer(Input=reader)streamTracer.SeedType = 'Point Cloud'streamTracer.SeedType.NumberOfPoints = 100# Render and saverenderView = GetActiveView()renderView.ViewSize = [1920, 1080]renderView.CameraPosition = [10, 5, 10]renderView.CameraFocalPoint = [0, 0, 0]SaveScreenshot('pressure_slice.png', renderView)# Create animationanimationScene = GetAnimationScene()animationScene.NumberOfFrames = 100SaveAnimation('flow_animation.avi', renderView)```**Transient Flow Animation:**```python# animate_transient_flow.pyfrom paraview.simple import *# Load time-series datareader = OpenDataFile("cases/drs_activation/VTK/drs_*.vtk")# Vorticity isosurface (Q-criterion)calculator = Calculator(Input=reader)calculator.Function = 'mag(vorticity)'contour = Contour(Input=calculator)contour.ContourBy = ['POINTS', 'Result']contour.Isosurfaces = [100, 200, 300]  # Vorticity levels# Color by velocity magnitudecontourDisplay = Show(contour)contourDisplay.ColorArrayName = ['POINTS', 'U']# Animate through time stepsanimationScene = GetAnimationScene()animationScene.PlayMode = 'Sequence'animationScene.NumberOfFrames = 200# Save as MP4SaveAnimation('drs_vorticity.mp4', renderView, FrameRate=30)```**Reference:** Quantum-Aero F1 Prototype TASKS.md:106---##### PyVista (Python 3D Visualization)**Description:** Python-friendly 3D visualization library built on VTK.**Installation:**```bashpip install pyvista[all]```**Advantages:**- Pythonic API (easier than ParaView scripting)- Jupyter notebook integration- GPU-accelerated rendering**Example:**```python# pyvista_visualization.pyimport pyvista as pvimport numpy as np# Load mesh and flow fieldmesh = pv.read("wing.vtk")# Plot pressure on surfaceplotter = pv.Plotter()plotter.add_mesh(    mesh,    scalars="pressure",    cmap="coolwarm",    show_edges=False,    lighting=True)plotter.add_scalar_bar(title="Pressure [Pa]")plotter.show()# Streamlinesstreamlines = mesh.streamlines(    vectors="velocity",    source_center=(0, 0, 0),    source_radius=1.0,    n_points=50)plotter = pv.Plotter()plotter.add_mesh(mesh, opacity=0.3, color="lightgray")plotter.add_mesh(streamlines, color="velocity", line_width=3)plotter.show()# Interactive widget in Jupyter# mesh.plot(jupyter_backend='trame', scalars='pressure')```**Web-Based Visualization:**```python# Export for web viewingmesh.save("wing_pressure.html")  # Interactive HTML file```---##### VisIt (DOE Visualization Tool)**Description:** High-performance visualization for extreme-scale data.**Use Cases:**- Massive datasets (>1B cells)- Parallel visualization (MPI)- Remote rendering on HPC**Installation:**```bash# Download from: https://visit-dav.github.io/visit-website/```---#### Category 2: Commercial Visualization##### Tecplot 360**Description:** Industry-standard commercial CFD visualization.**Advantages:**- Best-in-class streamline quality- XY plotting for quantitative analysis- Layout templates for reports**Cost:** $3,000-$10,000/year (academic discounts available)**Note:** For academic/non-commercial use only in this project.---#### Category 3: Web-Based Interactive Visualization##### Three.js + VTK.js (Project Integration)**Already Integrated** in frontend (Phase 5.2)**Capabilities:**- WebGL rendering in browser- Interactive camera controls- Real-time pressure colormap updates**Reference:** Quantum-Aero F1 Prototype DESIGN.md:26-30, TASKS.md:104-107---##### Plotly Dash (Interactive Dashboards)**Description:** Web-based plotting library for interactive dashboards.**Installation:**```bashpip install plotly dash```**Example Dashboard:**```python# dash_aero_dashboard.pyimport dashfrom dash import dcc, htmlimport plotly.graph_objects as goimport numpy as npapp = dash.Dash(__name__)# Load aerodynamic datadata = load_simulation_results()# Create 3D surface plotfig = go.Figure(data=[go.Surface(    x=data["x"],    y=data["y"],    z=data["pressure"],    colorscale="RdBu",    colorbar=dict(title="Pressure [Pa]"))])fig.update_layout(    title="F1 Wing Pressure Distribution",    scene=dict(        xaxis_title="Chordwise [m]",        yaxis_title="Spanwise [m]",        zaxis_title="Pressure [Pa]"    ))app.layout = html.Div([    html.H1("Aerodynamic Analysis Dashboard"),    dcc.Graph(figure=fig),    dcc.Slider(        id='alpha-slider',        min=0, max=15, step=0.5, value=5,        marks={i: f'{i}┬░' for i in range(0, 16, 3)}    )])if __name__ == '__main__':    app.run_server(debug=True, port=8050)```---### Dynamic Flow Visualization Techniques#### Technique 1: Streamlines (Steady Flow)**Definition:** Lines tangent to velocity field at every point.**Use Cases:**- Visualize flow direction- Identify separation points- Trace wake patterns**Implementation (ParaView):**```pythonstreamTracer = StreamTracer(Input=mesh)streamTracer.SeedType = 'Line'streamTracer.SeedType.Point1 = [-2, 0, 0]  # UpstreamstreamTracer.SeedType.Point2 = [-2, 2, 0]  # SpanstreamTracer.SeedType.Resolution = 50Show(streamTracer)```---#### Technique 2: Vortex Identification (Q-Criterion)**Definition:** Isosurfaces of $Q = \frac{1}{2}(\|\boldsymbol{\Omega}\|^2 - \|\mathbf{S}\|^2) > 0$Where:- $\boldsymbol{\Omega}$ = Vorticity tensor (rotation)- $\mathbf{S}$ = Strain rate tensor (deformation)**Use Cases:**- Identify vortex cores- Wing tip vortices- Floor edge vortices**Implementation:**```python# Q-criterion calculationcalculator = Calculator(Input=mesh)calculator.Function = '0.5 * (mag(vorticity)^2 - mag(strain)^2)'contour = Contour(Input=calculator)contour.Isosurfaces = [1000]  # Q > 1000```---#### Technique 3: Pathlines (Transient Flow)**Definition:** Trajectories of individual fluid particles over time.**Use Cases:**- DRS activation transient- Corner exit flow evolution- Particle tracing**Implementation:**```pythonparticleTracer = ParticleTracer(Input=timeSeries)particleTracer.SeedType = 'Point Cloud'particleTracer.SeedType.NumberOfPoints = 1000# Animate particle motionanimationScene.Play()```---#### Technique 4: Volume Rendering**Definition:** Direct rendering of 3D scalar fields with opacity transfer function.**Use Cases:**- Visualize pressure gradients- Vorticity magnitude clouds- Turbulent kinetic energy**Implementation:**```pythonvolumeRepresentation = GetDisplayProperties(mesh)volumeRepresentation.Representation = 'Volume'volumeRepresentation.ScalarOpacityFunction = pressureOpacity```---### Integration into Q-Aero Project#### Phase 1: Data Generation Pipeline (Weeks 1-3)**Week 1: NACA Database Generation**```bash# Task 1.2.1: Generate NACA airfoil database with XFOILpython scripts/generate_naca_dataset.py --n_airfoils=20 --reynolds=[1e6,3e6,6e6] --output=data/naca_database.h5# Expected output: 20 airfoils ├ù 3 Reynolds ├ù 50 alpha = 3,000 data points# Time: ~2 hours```**Week 2: OpenFOAM Baseline Simulations**```bash# Task 1.2.2: Run OpenFOAM on 100 wing configurationspython scripts/run_openfoam_batch.py --geometries=data/wing_library/ --n_cases=100# Expected output: 100 CFD cases ├ù 10 hours = 1,000 CPU-hours# Parallel execution: 10 CPUs ÔåÆ 100 hours wall time (4 days)```**Week 3: VLM Medium-Fidelity Dataset**```bash# Task 1.2.3: Generate 10,000 VLM evaluations for surrogate trainingpython scripts/generate_vlm_dataset.py --n_samples=10000 --output=data/vlm_training.h5# Expected output: 10,000 cases ├ù 5 seconds = 14 hours```---#### Phase 3: ML Training Data (Weeks 7-10)**Week 7-8: Augmented Dataset**```python# Use GANs to generate 1,000 synthetic geometriespython scripts/train_geometry_gan.py --real_data=data/wing_library/ --epochs=5000python scripts/generate_synthetic_wings.py --n_samples=1000 --output=data/synthetic_wings/# Run CFD on synthetic designspython scripts/run_openfoam_batch.py --geometries=data/synthetic_wings/ --n_cases=1000```**Deliverable:**- 1,100 total CFD simulations (100 real + 1,000 synthetic)- 10,000 VLM evaluations- 3,000 NACA airfoil data points---#### Phase 5: Frontend Visualization (Weeks 16-17)**Integration with Three.js/VTK.js:**```javascript// frontend/components/FlowVisualizer.jsximport { VTKViewer } from '@kitware/vtk.js';import { useEffect } from 'react';export default function FlowVisualizer({ resultId }) {  useEffect(() => {    // Fetch VTK data from backend    fetch(`/api/v1/results/${resultId}/vtk`)      .then(res => res.blob())      .then(blob => {        // Render with VTK.js        const reader = vtkXMLPolyDataReader.newInstance();        reader.parseAsArrayBuffer(blob);        const mapper = vtkMapper.newInstance();        mapper.setInputConnection(reader.getOutputPort());        const actor = vtkActor.newInstance();        actor.setMapper(mapper);        // Add to scene        renderer.addActor(actor);        renderWindow.render();      });  }, [resultId]);  return <div id="vtk-container" style={{ width: '100%', height: '600px' }} />;}```---### Data Storage Strategy#### HDF5 Format (Recommended)**Structure:**```aerodynamic_dataset.h5Ôö£ÔöÇÔöÇ /geometriesÔöé   Ôö£ÔöÇÔöÇ wing_001Ôöé   Ôöé   Ôö£ÔöÇÔöÇ vertices [N, 3]Ôöé   Ôöé   Ôö£ÔöÇÔöÇ faces [M, 3]Ôöé   Ôöé   ÔööÔöÇÔöÇ metadata (attrs: name, type, date)Ôöé   Ôö£ÔöÇÔöÇ wing_002Ôöé   ÔööÔöÇÔöÇ ...Ôö£ÔöÇÔöÇ /simulationsÔöé   Ôö£ÔöÇÔöÇ sim_001Ôöé   Ôöé   Ôö£ÔöÇÔöÇ /fieldsÔöé   Ôöé   Ôöé   Ôö£ÔöÇÔöÇ pressure [N]Ôöé   Ôöé   Ôöé   Ôö£ÔöÇÔöÇ velocity [N, 3]Ôöé   Ôöé   Ôöé   ÔööÔöÇÔöÇ vorticity [N, 3]Ôöé   Ôöé   Ôö£ÔöÇÔöÇ /forcesÔöé   Ôöé   Ôöé   Ôö£ÔöÇÔöÇ ClÔöé   Ôöé   Ôöé   Ôö£ÔöÇÔöÇ CdÔöé   Ôöé   Ôöé   ÔööÔöÇÔöÇ L_DÔöé   Ôöé   ÔööÔöÇÔöÇ /parameters (attrs: velocity, alpha, yaw)Ôöé   Ôö£ÔöÇÔöÇ sim_002Ôöé   ÔööÔöÇÔöÇ ...ÔööÔöÇÔöÇ /metadata    ÔööÔöÇÔöÇ dataset_info (attrs: version, date, n_cases)```**Loading Example:**```pythonimport h5pyimport numpy as npwith h5py.File("aerodynamic_dataset.h5", "r") as f:    # Load geometry    vertices = f["/geometries/wing_001/vertices"][:]    # Load simulation results    pressure = f["/simulations/sim_001/fields/pressure"][:]    Cl = f["/simulations/sim_001/forces"].attrs["Cl"]    # Load metadata    velocity = f["/simulations/sim_001/parameters"].attrs["velocity"]```---### Budget & Resource Requirements| Resource | Quantity | Cost | Purpose ||----------|----------|------|---------|| **GPU (RTX 4090)** | 1 | $1,500 | ML training, PyFR || **CPU Server (32 cores)** | 1 | $2,000 | OpenFOAM parallel || **Storage (2TB SSD)** | 1 | $200 | Dataset storage || **Cloud GPU (AWS p3.2xlarge)** | 100 hours | $300 | Overflow CFD || **ParaView License** | - | Free | Visualization || **XFOIL** | - | Free | Airfoil analysis || **OpenFOAM** | - | Free | CFD simulations || **Total** | - | **$4,000** | One-time hardware |---### Summary & Recommendations**Recommended Workflow:**1. **Weeks 1-3 (Phase 1):**   - Generate NACA database with XFOIL (3K data points)   - Run 100 OpenFOAM baseline cases   - Generate 10K VLM evaluations2. **Weeks 7-10 (Phase 3):**   - Train GAN on real geometries   - Generate 1K synthetic designs   - Run CFD on synthetic cases   - Train ML surrogate on combined dataset3. **Weeks 16-17 (Phase 5):**   - Integrate ParaView/PyVista for offline analysis   - Implement Three.js/VTK.js for web visualization   - Create interactive dashboards with Plotly Dash**Key Takeaways:**- **OpenFOAM** = High-fidelity validation (100s of cases)- **VLM** = Medium-fidelity (1,000s of cases)- **ML Surrogate** = Low-fidelity (millions of evaluations)- **ParaView** = Primary visualization tool (open-source, powerful)- **UIUC + NASA** = Real data sources (1,600+ airfoils, validated CFD)---## Local Development Setup (RTX 4070 Proof of Concept)### OverviewThis section provides **complete configuration** for running the Quantum-Aero prototype on a personal computer with **NVIDIA GeForce RTX 4070** GPU. This is the **proof-of-concept environment** before production deployment.**Target Hardware:**- GPU: NVIDIA GeForce RTX 4070 (12GB VRAM)- CPU: Intel i7/i9 or AMD Ryzen 7/9 (8+ cores recommended)- RAM: 32GB minimum, 64GB recommended- Storage: 1TB NVMe SSD (for datasets and models)- OS: Ubuntu 22.04 LTS or Windows 11 with WSL2---### RTX 4070 Specifications & Performance Expectations#### Hardware Specifications| Specification | RTX 4070 | Notes ||---------------|----------|-------|| **CUDA Cores** | 5,888 | ~70% of RTX 4090 || **Tensor Cores** | 184 (4th Gen) | FP16/FP8 acceleration || **VRAM** | 12GB GDDR6X | Sufficient for most models || **Memory Bandwidth** | 504 GB/s | High-speed access || **TDP** | 200W | Power-efficient || **CUDA Compute** | 8.9 | Latest architecture || **PCIe** | 4.0 x16 | High bandwidth |#### Performance Expectations**ML Inference (ONNX Runtime GPU):**- **Surrogate Model:** 50-80ms per inference (target: <100ms Ô£ô)- **Batch Size:** 8-16 meshes simultaneously- **Throughput:** 12-20 inferences/second- **VRAM Usage:** 6-8GB for typical model**ML Training (PyTorch CUDA):**- **Training Time:** ~8-12 hours for baseline model (vs. 6 hours on RTX 4090)- **Batch Size:** 12-16 (vs. 20-24 on RTX 4090)- **Mixed Precision (FP16):** 1.8x speedup over FP32- **Epochs:** 100 epochs in ~10 hours**CFD/Physics (PyFR GPU):**- **Speedup:** 15-25x vs. CPU (vs. 30-40x on RTX 4090)- **Mesh Size:** Up to 2M cells (vs. 5M on RTX 4090)- **Stable & Sufficient:** Ô£ô for proof-of-concept**Quantum Simulation (Qiskit Aer):**- **Qubits:** CPU-bound, GPU not utilized- **No GPU bottleneck:** Ô£ô**Conclusion:** RTX 4070 is **excellent** for proof-of-concept. All performance targets achievable.---### System Prerequisites#### 1. NVIDIA Driver Installation**Ubuntu 22.04:**```bash# Check current GPUlspci | grep -i nvidia# Remove old drivers (if any)sudo apt-get purge nvidia* -ysudo apt-get autoremove -y# Add NVIDIA PPAsudo add-apt-repository ppa:graphics-drivers/ppa -ysudo apt-get update# Install latest driver (545+ for RTX 4070)sudo ubuntu-drivers devices  # Check recommendedsudo apt-get install nvidia-driver-545 -y# Rebootsudo reboot# Verify installationnvidia-smi```**Expected Output:**```+-----------------------------------------------------------------------------------------+| NVIDIA-SMI 545.xx                 Driver Version: 545.xx         CUDA Version: 12.3     ||---------|----------------------|----------------------|----------------------------|| GPU  Name                 TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC ||===============================+======================+============================||   0  NVIDIA GeForce RTX 4070      | 00000000:01:00.0  On |                  N/A ||---------|----------------------|----------------------|----------------------------|```**Windows 11 + WSL2:**```powershell# Download from NVIDIA website# https://www.nvidia.com/Download/index.aspx# Install WSL2 with Ubuntuwsl --install -d Ubuntu-22.04# Install CUDA in WSL2wslsudo apt-get updatesudo apt-get install -y nvidia-cuda-toolkit```---#### 2. CUDA Toolkit Installation```bash# Ubuntu 22.04wget https://developer.download.nvidia.com/compute/cuda/12.3.0/local_installers/cuda_12.3.0_545.23.06_linux.runsudo sh cuda_12.3.0_545.23.06_linux.run --silent --toolkit# Add to PATHecho 'export PATH=/usr/local/cuda-12.3/bin:$PATH' >> ~/.bashrcecho 'export LD_LIBRARY_PATH=/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH' >> ~/.bashrcsource ~/.bashrc# Verifynvcc --version```**Expected Output:**```nvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2023 NVIDIA CorporationBuilt on Mon_Sep_11_22:00:00_PDT_2023Cuda compilation tools, release 12.3, V12.3.0```---#### 3. Docker with GPU Support**Install Docker:**```bash# Remove old versionssudo apt-get remove docker docker-engine docker.io containerd runc# Install Dockercurl -fsSL https://get.docker.com -o get-docker.shsudo sh get-docker.sh# Add user to docker groupsudo usermod -aG docker $USERnewgrp docker# Verifydocker --version```**Install NVIDIA Container Toolkit:**```bash# Add NVIDIA Docker repositorydistribution=$(. /etc/os-release;echo $ID$VERSION_ID)curl -s -L https://nvidia.github.io/libnvidia-container/gpgkey | sudo apt-key add -curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list# Installsudo apt-get updatesudo apt-get install -y nvidia-container-toolkit# Configure Dockersudo nvidia-ctk runtime configure --runtime=dockersudo systemctl restart docker# Test GPU access in Dockerdocker run --rm --gpus all nvidia/cuda:12.3.0-base-ubuntu22.04 nvidia-smi```**Expected Output:** Same `nvidia-smi` output as host.---#### 4. Development Environment**Python 3.11 with CUDA:**```bash# Install Python 3.11sudo apt-get install -y python3.11 python3.11-venv python3.11-dev# Create virtual environmentpython3.11 -m venv ~/qaero-envsource ~/qaero-env/bin/activate# Install PyTorch with CUDA 12.1 supportpip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121# Verify GPU accesspython -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}'); print(f'GPU: {torch.cuda.get_device_name(0)}')"```**Expected Output:**```CUDA Available: TrueGPU: NVIDIA GeForce RTX 4070```**Node.js 20:**```bash# Install Node.js 20curl -fsSL https://deb.nodesource.com/setup_20.x | sudo -E bash -sudo apt-get install -y nodejs# Verifynode --version  # v20.x.xnpm --version   # 10.x.x```---### Resource Allocation for RTX 4070#### GPU Memory Management**Total VRAM:** 12GB**Allocation Strategy:**| Component | VRAM Allocation | Usage ||-----------|----------------|-------|| **ML Inference Service** | 6-7GB | ONNX model + batch processing || **ML Training** | 10-11GB | During training only (exclusive) || **System Reserve** | 1-2GB | Display, OS, buffers || **PyFR (Optional)** | 8-10GB | If running CFD on GPU |**Configuration:**```python# services/ml_inference/config.pyimport torch# RTX 4070 specific settingsGPU_CONFIG = {    "device": "cuda:0",    "max_batch_size": 12,  # Conservative for 12GB VRAM    "fp16_mode": True,     # Use mixed precision    "memory_fraction": 0.9, # Use 90% of available VRAM}# Set memory fractiontorch.cuda.set_per_process_memory_fraction(0.9, device=0)# Enable TF32 for faster matmul on Tensor Corestorch.backends.cuda.matmul.allow_tf32 = Truetorch.backends.cudnn.allow_tf32 = True```---#### CPU & RAM Allocation**Docker Resource Limits:**```yaml# docker-compose.yml (RTX 4070 optimized)services:  ml-service:    deploy:      resources:        limits:          cpus: '4.0'      # 4 cores for ML service          memory: 16G      # 16GB RAM        reservations:          devices:            - driver: nvidia              count: 1              capabilities: [gpu]          memory: 8G  physics-service:    deploy:      resources:        limits:          cpus: '8.0'      # 8 cores for physics (no GPU)          memory: 16G  quantum-service:    deploy:      resources:        limits:          cpus: '4.0'          memory: 8G  backend:    deploy:      resources:        limits:          cpus: '2.0'          memory: 4G  frontend:    deploy:      resources:        limits:          cpus: '2.0'          memory: 2G  mongodb:    deploy:      resources:        limits:          cpus: '2.0'          memory: 4G  redis:    deploy:      resources:        limits:          cpus: '1.0'          memory: 2G```**Total:** 23 cores, 52GB RAM (fits 32GB with swapping, ideal with 64GB)---### Local Development Workflow#### 1. Clone Repository```bash# Clone projectgit clone https://github.com/your-org/quantum-aero.gitcd quantum-aero# Verify directory structuretree -L 2```**Expected Structure:**```quantum-aero/Ôö£ÔöÇÔöÇ services/Ôöé   Ôö£ÔöÇÔöÇ ml_inference/Ôöé   Ôö£ÔöÇÔöÇ physics/Ôöé   Ôö£ÔöÇÔöÇ quantum/Ôöé   ÔööÔöÇÔöÇ fsi/Ôö£ÔöÇÔöÇ backend/Ôö£ÔöÇÔöÇ frontend/Ôö£ÔöÇÔöÇ scripts/Ôö£ÔöÇÔöÇ data/Ôö£ÔöÇÔöÇ models/Ôö£ÔöÇÔöÇ docker-compose.ymlÔö£ÔöÇÔöÇ docker-compose.dev.ymlÔööÔöÇÔöÇ README.md```---#### 2. Environment Configuration**Create `.env` file:**```bash# .env.local (for RTX 4070 development)# Copy to .envNODE_ENV=developmentLOG_LEVEL=debug# GPU ConfigurationCUDA_VISIBLE_DEVICES=0GPU_MEMORY_FRACTION=0.9ENABLE_FP16=trueBATCH_SIZE=12# PortsML_SERVICE_PORT=8000PHYSICS_SERVICE_PORT=8001QUANTUM_SERVICE_PORT=8002FSI_SERVICE_PORT=8003BACKEND_PORT=4000FRONTEND_PORT=3000# DatabaseMONGODB_URI=mongodb://mongodb:27017/qaero_devREDIS_URL=redis://redis:6379# AuthenticationJWT_SECRET=your-secret-key-change-in-productionJWT_EXPIRY=24h# PathsDATA_DIR=/app/dataMODELS_DIR=/app/modelsCACHE_DIR=/app/cache# PerformanceWORKERS=4THREADS_PER_WORKER=2```---#### 3. Build & Start Services**Development Mode (with hot reload):**```bash# Build all imagesdocker-compose -f docker-compose.dev.yml build# Start servicesdocker-compose -f docker-compose.dev.yml up -d# View logsdocker-compose logs -f# Check GPU access in ML servicedocker-compose exec ml-service nvidia-smi# Check service healthcurl http://localhost:8000/health  # ML servicecurl http://localhost:8001/health  # Physics servicecurl http://localhost:8002/health  # Quantum servicecurl http://localhost:4000/health  # Backendcurl http://localhost:3000          # Frontend```**Expected Startup Time:**- Cold start: 2-3 minutes (first time, pulling images)- Warm start: 30-60 seconds---#### 4. Run Sample Inference**Test ML Inference:**```bash# Upload test meshcurl -X POST http://localhost:8000/api/v1/predict-pressure \  -F "mesh=@data/test_meshes/naca0012.stl" \  -F "velocity=250" \  -F "yaw=0"# Expected response time: 50-80ms (RTX 4070)```**Test Physics Service:**```bashcurl -X POST http://localhost:8001/api/v1/vlm-solve \  -F "mesh=@data/test_meshes/wing.stl" \  -F "velocity=250" \  -F "alpha=5"# Expected response time: 5-10 seconds```---#### 5. Monitor GPU Usage**Real-Time Monitoring:**```bash# Terminal 1: Watch GPU usagewatch -n 1 nvidia-smi# Terminal 2: Monitor Docker statsdocker stats# Terminal 3: Check ML service logsdocker-compose logs -f ml-service```**Key Metrics to Watch:**- **GPU Utilization:** Should be 80-95% during inference- **GPU Memory:** 6-7GB used (out of 12GB)- **GPU Temperature:** <75┬░C (good), <85┬░C (acceptable)- **Power Draw:** 150-180W (out of 200W TDP)---### Performance Benchmarking#### Benchmark Script```python# scripts/benchmark_rtx4070.pyimport timeimport torchimport onnxruntime as ortimport numpy as npdef benchmark_inference(model_path, n_iterations=100):    """Benchmark ML inference on RTX 4070."""    # Load ONNX model    providers = [        ('CUDAExecutionProvider', {            'device_id': 0,            'gpu_mem_limit': 8 * 1024 * 1024 * 1024,  # 8GB        }),        'CPUExecutionProvider'    ]    session = ort.InferenceSession(model_path, providers=providers)    # Dummy input (simulate mesh with 10K vertices)    input_name = session.get_inputs()[0].name    dummy_input = np.random.randn(1, 10000, 3).astype(np.float32)    # Warmup    for _ in range(10):        session.run(None, {input_name: dummy_input})    # Benchmark    torch.cuda.synchronize()    start = time.time()    for _ in range(n_iterations):        outputs = session.run(None, {input_name: dummy_input})    torch.cuda.synchronize()    elapsed = time.time() - start    avg_time = (elapsed / n_iterations) * 1000  # ms    throughput = n_iterations / elapsed    print(f"=== RTX 4070 Benchmark Results ===")    print(f"Model: {model_path}")    print(f"Iterations: {n_iterations}")    print(f"Average Inference Time: {avg_time:.2f} ms")    print(f"Throughput: {throughput:.2f} inferences/sec")    print(f"Target: <100ms Ô£ô" if avg_time < 100 else "Target: <100ms Ô£ù")    return avg_time, throughputif __name__ == "__main__":    # Run benchmark    model_path = "models/surrogate_v1.onnx"    avg_time, throughput = benchmark_inference(model_path, n_iterations=100)    # GPU info    print(f"\nGPU: {torch.cuda.get_device_name(0)}")    print(f"CUDA Version: {torch.version.cuda}")    print(f"PyTorch Version: {torch.__version__}")    print(f"VRAM Available: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")```**Run Benchmark:**```bashpython scripts/benchmark_rtx4070.py```**Expected Output:**```=== RTX 4070 Benchmark Results ===Model: models/surrogate_v1.onnxIterations: 100Average Inference Time: 67.34 msThroughput: 14.85 inferences/secTarget: <100ms Ô£ôGPU: NVIDIA GeForce RTX 4070CUDA Version: 12.1PyTorch Version: 2.1.0+cu121VRAM Available: 12.00 GB```---### Optimization Tips for RTX 4070#### 1. Enable Mixed Precision (FP16)**Benefits:**- 1.8-2.0x faster inference- 50% less VRAM usage- Minimal accuracy loss (<0.5%)**Implementation:**```python# services/ml_inference/model.pyimport torchfrom torch.cuda.amp import autocastclass SurrogateModel:    def __init__(self, model_path):        self.model = torch.jit.load(model_path).cuda()        self.model.eval()    @torch.no_grad()    @autocast()  # Automatic mixed precision    def predict(self, input_tensor):        with torch.cuda.amp.autocast():            output = self.model(input_tensor.half())  # FP16        return output.float()  # Convert back to FP32 for output```---#### 2. Batch Processing**Strategy:** Process multiple meshes simultaneously.**Implementation:**```python# Process 12 meshes at once (RTX 4070 sweet spot)batch_size = 12meshes = load_meshes(mesh_files[:batch_size])predictions = model.predict_batch(meshes)```**Performance Gain:** 8-10x throughput vs. sequential processing.---#### 3. CUDA Graphs (Advanced)**Benefits:**- Reduce kernel launch overhead- 10-15% faster for repeated operations**Implementation:**```python# Capture CUDA graphstatic_input = torch.randn(1, 10000, 3).cuda()s = torch.cuda.Stream()s.wait_stream(torch.cuda.current_stream())with torch.cuda.stream(s):    for _ in range(3):  # Warmup        static_output = model(static_input)s.synchronize()# Capture graphg = torch.cuda.CUDAGraph()with torch.cuda.graph(g):    static_output = model(static_input)# Replay graph (much faster)g.replay()```---#### 4. Optimize Docker Performance**Best Practices:**```dockerfile# services/ml_inference/DockerfileFROM nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04# Install dependenciesRUN apt-get update && apt-get install -y \    python3.11 python3-pip \    && rm -rf /var/lib/apt/lists/*# Copy requirementsCOPY requirements.txt .RUN pip install --no-cache-dir -r requirements.txt# Copy applicationCOPY . /appWORKDIR /app# Optimize CUDA settings for RTX 4070ENV CUDA_VISIBLE_DEVICES=0ENV CUDA_DEVICE_ORDER=PCI_BUS_IDENV TF_FORCE_GPU_ALLOW_GROWTH=true# Expose portEXPOSE 8000# Run with optimized settingsCMD ["python", "-u", "main.py"]```---### Troubleshooting#### Issue 1: "CUDA out of memory"**Solution:**```python# Reduce batch sizeBATCH_SIZE = 8  # Instead of 12# Or enable gradient checkpointingtorch.utils.checkpoint.checkpoint(model, inputs)# Or clear cache between runstorch.cuda.empty_cache()```---#### Issue 2: "nvidia-smi not found in Docker"**Solution:**```bash# Verify NVIDIA runtimedocker run --rm --gpus all nvidia/cuda:12.1.0-base-ubuntu22.04 nvidia-smi# If fails, reconfigure Dockersudo nvidia-ctk runtime configure --runtime=dockersudo systemctl restart docker```---#### Issue 3: Slow inference (>150ms)**Checklist:**```bash# 1. Check GPU utilizationnvidia-smi# 2. Verify FP16 enabledgrep "ENABLE_FP16" .env  # Should be true# 3. Check batch sizegrep "BATCH_SIZE" .env  # Should be 8-12# 4. Restart servicedocker-compose restart ml-service# 5. Run benchmarkpython scripts/benchmark_rtx4070.py```---### Proof of Concept Validation Checklist**Before proceeding to production:**- [ ] RTX 4070 drivers installed and verified (`nvidia-smi`)- [ ] CUDA 12.1+ toolkit installed (`nvcc --version`)- [ ] Docker with GPU support working (`docker run --gpus all nvidia/cuda nvidia-smi`)- [ ] All services starting successfully (`docker-compose up -d`)- [ ] ML inference <100ms (run `scripts/benchmark_rtx4070.py`)- [ ] GPU memory usage 6-8GB during inference- [ ] No CUDA OOM errors during 1-hour stress test- [ ] Frontend accessible at `http://localhost:3000`- [ ] Can upload mesh and view results end-to-end- [ ] All integration tests passing (`npm test`, `pytest`)---## Production-Ready Docker & Microservices Architecture### OverviewThis section provides **complete production deployment** configuration with Docker orchestration, CI/CD pipelines, monitoring, logging, and scaling strategies.**Production Environment:**- Cloud: AWS, Azure, or GCP (or on-premise GPU servers)- Orchestration: Docker Swarm or Kubernetes- Monitoring: Prometheus + Grafana- Logging: ELK Stack (Elasticsearch, Logstash, Kibana)- CI/CD: GitHub Actions- Load Balancing: NGINX- SSL/TLS: Let's Encrypt---### Complete Docker Compose Configuration#### Production docker-compose.yml```yaml# docker-compose.production.ymlversion: '3.8'networks:  frontend:    driver: bridge  backend:    driver: bridge  internal:    driver: bridge    internal: true  # No external accessvolumes:  mongo-data:  redis-data:  prometheus-data:  grafana-data:  model-cache:services:  # ============================================  # FRONTEND LAYER  # ============================================  frontend:    image: qaero/frontend:${VERSION:-latest}    build:      context: ./frontend      dockerfile: Dockerfile.production      args:        NEXT_PUBLIC_API_URL: ${API_URL}    container_name: qaero-frontend    restart: unless-stopped    networks:      - frontend    environment:      - NODE_ENV=production      - NEXT_PUBLIC_API_URL=${API_URL}    deploy:      resources:        limits:          cpus: '2.0'          memory: 2G        reservations:          memory: 1G    healthcheck:      test: ["CMD", "curl", "-f", "http://localhost:3000/api/health"]      interval: 30s      timeout: 10s      retries: 3      start_period: 60s    logging:      driver: "json-file"      options:        max-size: "50m"        max-file: "5"    labels:      - "com.qaero.service=frontend"      - "com.qaero.version=${VERSION}"  # ============================================  # API GATEWAY / LOAD BALANCER  # ============================================  nginx:    image: nginx:alpine    container_name: qaero-nginx    restart: unless-stopped    ports:      - "80:80"      - "443:443"    networks:      - frontend      - backend    volumes:      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro      - ./nginx/ssl:/etc/nginx/ssl:ro      - ./nginx/cache:/var/cache/nginx    depends_on:      - frontend      - backend    deploy:      resources:        limits:          cpus: '2.0'          memory: 1G    healthcheck:      test: ["CMD", "nginx", "-t"]      interval: 30s      timeout: 10s      retries: 3    logging:      driver: "json-file"      options:        max-size: "100m"        max-file: "10"  # ============================================  # BACKEND LAYER  # ============================================  backend:    image: qaero/backend:${VERSION:-latest}    build:      context: ./backend      dockerfile: Dockerfile.production    container_name: qaero-backend    restart: unless-stopped    networks:      - backend      - internal    environment:      - NODE_ENV=production      - PORT=4000      - MONGODB_URI=mongodb://mongodb:27017/qaero      - REDIS_URL=redis://redis:6379      - JWT_SECRET=${JWT_SECRET}      - JWT_EXPIRY=24h      - LOG_LEVEL=info      - ML_SERVICE_URL=http://ml-service:8000      - PHYSICS_SERVICE_URL=http://physics-service:8001      - QUANTUM_SERVICE_URL=http://quantum-service:8002      - FSI_SERVICE_URL=http://fsi-service:8003    depends_on:      - mongodb      - redis      - ml-service      - physics-service      - quantum-service    deploy:      replicas: 3  # Load balanced      resources:        limits:          cpus: '4.0'          memory: 8G        reservations:          memory: 4G    healthcheck:      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]      interval: 30s      timeout: 10s      retries: 3      start_period: 60s    logging:      driver: "json-file"      options:        max-size: "100m"        max-file: "10"  # ============================================  # MICROSERVICES LAYER  # ============================================  ml-service:    image: qaero/ml-inference:${VERSION:-latest}    build:      context: ./services/ml_inference      dockerfile: Dockerfile.production    container_name: qaero-ml-service    restart: unless-stopped    networks:      - internal    environment:      - CUDA_VISIBLE_DEVICES=0      - MODEL_PATH=/models/surrogate_v1.onnx      - BATCH_SIZE=16      - ENABLE_FP16=true      - LOG_LEVEL=info      - REDIS_URL=redis://redis:6379    volumes:      - model-cache:/models:ro      - ./data:/data:ro    depends_on:      - redis    deploy:      replicas: 2  # Scale for load      resources:        limits:          cpus: '8.0'          memory: 24G        reservations:          memory: 16G          devices:            - driver: nvidia              count: 1              capabilities: [gpu]    healthcheck:      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]      interval: 30s      timeout: 10s      retries: 3      start_period: 120s    logging:      driver: "json-file"      options:        max-size: "200m"        max-file: "10"  physics-service:    image: qaero/physics:${VERSION:-latest}    build:      context: ./services/physics      dockerfile: Dockerfile.production    container_name: qaero-physics-service    restart: unless-stopped    networks:      - internal    environment:      - VLM_CACHE_SIZE=1000      - REDIS_URL=redis://redis:6379      - LOG_LEVEL=info    volumes:      - ./cache:/cache    depends_on:      - redis    deploy:      replicas: 3      resources:        limits:          cpus: '12.0'          memory: 24G        reservations:          memory: 16G    healthcheck:      test: ["CMD", "curl", "-f", "http://localhost:8001/health"]      interval: 30s      timeout: 10s      retries: 3    logging:      driver: "json-file"      options:        max-size: "100m"        max-file: "10"  quantum-service:    image: qaero/quantum:${VERSION:-latest}    build:      context: ./services/quantum      dockerfile: Dockerfile.production    container_name: qaero-quantum-service    restart: unless-stopped    networks:      - internal    environment:      - QISKIT_BACKEND=aer_simulator      - QAOA_MAX_LAYERS=5      - LOG_LEVEL=info    deploy:      replicas: 2      resources:        limits:          cpus: '8.0'          memory: 16G        reservations:          memory: 8G    healthcheck:      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]      interval: 30s      timeout: 10s      retries: 3    logging:      driver: "json-file"      options:        max-size: "100m"        max-file: "10"  fsi-service:    image: qaero/fsi:${VERSION:-latest}    build:      context: ./services/fsi      dockerfile: Dockerfile.production    container_name: qaero-fsi-service    restart: unless-stopped    networks:      - internal    environment:      - OPENFOAM_VERSION=10      - LOG_LEVEL=info    volumes:      - ./simulations:/simulations    deploy:      replicas: 1  # Heavy computation, sequential      resources:        limits:          cpus: '16.0'          memory: 32G        reservations:          memory: 24G    healthcheck:      test: ["CMD", "curl", "-f", "http://localhost:8003/health"]      interval: 60s      timeout: 20s      retries: 3    logging:      driver: "json-file"      options:        max-size: "500m"        max-file: "5"  # ============================================  # DATA LAYER  # ============================================  mongodb:    image: mongo:7    container_name: qaero-mongodb    restart: unless-stopped    networks:      - internal    environment:      - MONGO_INITDB_ROOT_USERNAME=${MONGO_ROOT_USER}      - MONGO_INITDB_ROOT_PASSWORD=${MONGO_ROOT_PASSWORD}      - MONGO_INITDB_DATABASE=qaero    volumes:      - mongo-data:/data/db      - ./mongo-init.js:/docker-entrypoint-initdb.d/init.js:ro    deploy:      resources:        limits:          cpus: '4.0'          memory: 8G        reservations:          memory: 4G    healthcheck:      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]      interval: 30s      timeout: 10s      retries: 3    logging:      driver: "json-file"      options:        max-size: "100m"        max-file: "10"    command: ["mongod", "--auth", "--wiredTigerCacheSizeGB", "4"]  redis:    image: redis:7-alpine    container_name: qaero-redis    restart: unless-stopped    networks:      - internal    volumes:      - redis-data:/data    deploy:      resources:        limits:          cpus: '2.0'          memory: 4G        reservations:          memory: 2G    healthcheck:      test: ["CMD", "redis-cli", "ping"]      interval: 30s      timeout: 10s      retries: 3    logging:      driver: "json-file"      options:        max-size: "50m"        max-file: "5"    command: ["redis-server", "--appendonly", "yes", "--maxmemory", "3gb", "--maxmemory-policy", "allkeys-lru"]  # ============================================  # MONITORING & OBSERVABILITY  # ============================================  prometheus:    image: prom/prometheus:latest    container_name: qaero-prometheus    restart: unless-stopped    networks:      - internal      - backend    ports:      - "9090:9090"    volumes:      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro      - prometheus-data:/prometheus    command:      - '--config.file=/etc/prometheus/prometheus.yml'      - '--storage.tsdb.path=/prometheus'      - '--storage.tsdb.retention.time=30d'    deploy:      resources:        limits:          cpus: '2.0'          memory: 4G    logging:      driver: "json-file"      options:        max-size: "100m"        max-file: "5"  grafana:    image: grafana/grafana:latest    container_name: qaero-grafana    restart: unless-stopped    networks:      - backend    ports:      - "3001:3000"    environment:      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}      - GF_SERVER_ROOT_URL=https://${DOMAIN}/grafana    volumes:      - grafana-data:/var/lib/grafana      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards:ro      - ./grafana/datasources:/etc/grafana/provisioning/datasources:ro    depends_on:      - prometheus    deploy:      resources:        limits:          cpus: '1.0'          memory: 2G    logging:      driver: "json-file"      options:        max-size: "50m"        max-file: "5"  node-exporter:    image: prom/node-exporter:latest    container_name: qaero-node-exporter    restart: unless-stopped    networks:      - internal    command:      - '--path.procfs=/host/proc'      - '--path.sysfs=/host/sys'      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'    volumes:      - /proc:/host/proc:ro      - /sys:/host/sys:ro      - /:/rootfs:ro    deploy:      resources:        limits:          cpus: '0.5'          memory: 512M  cadvisor:    image: gcr.io/cadvisor/cadvisor:latest    container_name: qaero-cadvisor    restart: unless-stopped    networks:      - internal    volumes:      - /:/rootfs:ro      - /var/run:/var/run:ro      - /sys:/sys:ro      - /var/lib/docker/:/var/lib/docker:ro      - /dev/disk/:/dev/disk:ro    privileged: true    deploy:      resources:        limits:          cpus: '1.0'          memory: 1G```---### NGINX Configuration**nginx/nginx.conf:**```nginx# Production NGINX Configurationuser nginx;worker_processes auto;error_log /var/log/nginx/error.log warn;pid /var/run/nginx.pid;events {    worker_connections 4096;    use epoll;    multi_accept on;}http {    include /etc/nginx/mime.types;    default_type application/octet-stream;    log_format main '$remote_addr - $remote_user [$time_local] "$request" '                    '$status $body_bytes_sent "$http_referer" '                    '"$http_user_agent" "$http_x_forwarded_for" '                    'rt=$request_time uct="$upstream_connect_time" '                    'uht="$upstream_header_time" urt="$upstream_response_time"';    access_log /var/log/nginx/access.log main;    sendfile on;    tcp_nopush on;    tcp_nodelay on;    keepalive_timeout 65;    types_hash_max_size 2048;    client_max_body_size 100M;  # Allow large mesh uploads    # Gzip compression    gzip on;    gzip_vary on;    gzip_proxied any;    gzip_comp_level 6;    gzip_types text/plain text/css text/xml text/javascript               application/json application/javascript application/xml+rss               application/rss+xml font/truetype font/opentype               application/vnd.ms-fontobject image/svg+xml;    # Rate limiting    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;    limit_req_zone $binary_remote_addr zone=upload_limit:10m rate=2r/s;    # Upstream backends    upstream backend_api {        least_conn;        server backend:4000 max_fails=3 fail_timeout=30s;        keepalive 32;    }    upstream frontend_app {        server frontend:3000 max_fails=3 fail_timeout=30s;        keepalive 32;    }    # HTTP to HTTPS redirect    server {        listen 80;        server_name ${DOMAIN};        return 301 https://$host$request_uri;    }    # HTTPS server    server {        listen 443 ssl http2;        server_name ${DOMAIN};        # SSL configuration        ssl_certificate /etc/nginx/ssl/cert.pem;        ssl_certificate_key /etc/nginx/ssl/key.pem;        ssl_protocols TLSv1.2 TLSv1.3;        ssl_ciphers HIGH:!aNULL:!MD5;        ssl_prefer_server_ciphers on;        ssl_session_cache shared:SSL:10m;        ssl_session_timeout 10m;        # Security headers        add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;        add_header X-Frame-Options "SAMEORIGIN" always;        add_header X-Content-Type-Options "nosniff" always;        add_header X-XSS-Protection "1; mode=block" always;        add_header Referrer-Policy "no-referrer-when-downgrade" always;        # Frontend        location / {            proxy_pass http://frontend_app;            proxy_http_version 1.1;            proxy_set_header Upgrade $http_upgrade;            proxy_set_header Connection 'upgrade';            proxy_set_header Host $host;            proxy_cache_bypass $http_upgrade;            proxy_set_header X-Real-IP $remote_addr;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Forwarded-Proto $scheme;        }        # Backend API        location /api/ {            limit_req zone=api_limit burst=20 nodelay;            proxy_pass http://backend_api;            proxy_http_version 1.1;            proxy_set_header Connection "";            proxy_set_header Host $host;            proxy_set_header X-Real-IP $remote_addr;            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;            proxy_set_header X-Forwarded-Proto $scheme;            # Timeouts for long-running requests            proxy_connect_timeout 60s;            proxy_send_timeout 600s;            proxy_read_timeout 600s;        }        # File uploads (mesh files)        location /api/upload/ {            limit_req zone=upload_limit burst=5 nodelay;            client_max_body_size 100M;            proxy_pass http://backend_api;            proxy_request_buffering off;            proxy_http_version 1.1;            proxy_set_header Connection "";            proxy_set_header Host $host;        }        # Health checks (no auth required)        location /health {            proxy_pass http://backend_api/health;            access_log off;        }        # Grafana monitoring        location /grafana/ {            proxy_pass http://grafana:3000/;            proxy_set_header Host $host;        }        # Static assets (cached)        location ~* \.(jpg|jpeg|png|gif|ico|css|js|svg|woff|woff2|ttf|eot)$ {            proxy_pass http://frontend_app;            expires 1y;            add_header Cache-Control "public, immutable";        }    }}```---### CI/CD Pipeline#### GitHub Actions Workflow**.github/workflows/ci-cd.yml:**```yamlname: Q-Aero CI/CD Pipelineon:  push:    branches: [main, develop]  pull_request:    branches: [main]  release:    types: [published]env:  REGISTRY: ghcr.io  IMAGE_NAME: ${{ github.repository }}jobs:  # ==========================================  # STAGE 1: Code Quality & Testing  # ==========================================  lint-and-test:    runs-on: ubuntu-latest    steps:      - name: Checkout code        uses: actions/checkout@v3      - name: Set up Node.js        uses: actions/setup-node@v3        with:          node-version: '20'          cache: 'npm'      - name: Set up Python        uses: actions/setup-python@v4        with:          python-version: '3.11'          cache: 'pip'      - name: Install dependencies        run: |          npm install          pip install -r requirements.txt      - name: Run ESLint        run: npm run lint      - name: Run Pylint        run: pylint **/*.py      - name: Run unit tests (JavaScript)        run: npm test -- --coverage      - name: Run unit tests (Python)        run: pytest --cov=services --cov-report=xml      - name: Upload coverage        uses: codecov/codecov-action@v3        with:          files: ./coverage/coverage-final.json,./coverage.xml  # ==========================================  # STAGE 2: Build Docker Images  # ==========================================  build-images:    needs: lint-and-test    runs-on: ubuntu-latest    permissions:      contents: read      packages: write    strategy:      matrix:        service:          - frontend          - backend          - ml-inference          - physics          - quantum          - fsi    steps:      - name: Checkout code        uses: actions/checkout@v3      - name: Log in to GitHub Container Registry        uses: docker/login-action@v2        with:          registry: ${{ env.REGISTRY }}          username: ${{ github.actor }}          password: ${{ secrets.GITHUB_TOKEN }}      - name: Extract metadata        id: meta        uses: docker/metadata-action@v4        with:          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/${{ matrix.service }}          tags: |            type=ref,event=branch            type=ref,event=pr            type=semver,pattern={{version}}            type=semver,pattern={{major}}.{{minor}}            type=sha      - name: Build and push Docker image        uses: docker/build-push-action@v4        with:          context: ./${{ matrix.service == 'ml-inference' && 'services/ml_inference' || matrix.service == 'physics' && 'services/physics' || matrix.service == 'quantum' && 'services/quantum' || matrix.service == 'fsi' && 'services/fsi' || matrix.service }}          file: ./${{ matrix.service == 'ml-inference' && 'services/ml_inference' || matrix.service == 'physics' && 'services/physics' || matrix.service == 'quantum' && 'services/quantum' || matrix.service == 'fsi' && 'services/fsi' || matrix.service }}/Dockerfile.production          push: true          tags: ${{ steps.meta.outputs.tags }}          labels: ${{ steps.meta.outputs.labels }}          cache-from: type=gha          cache-to: type=gha,mode=max  # ==========================================  # STAGE 3: Integration Testing  # ==========================================  integration-tests:    needs: build-images    runs-on: ubuntu-latest    services:      mongodb:        image: mongo:7        env:          MONGO_INITDB_ROOT_USERNAME: root          MONGO_INITDB_ROOT_PASSWORD: password        ports:          - 27017:27017      redis:        image: redis:7        ports:          - 6379:6379    steps:      - name: Checkout code        uses: actions/checkout@v3      - name: Set up Docker Compose        run: |          docker-compose -f docker-compose.test.yml pull          docker-compose -f docker-compose.test.yml up -d      - name: Wait for services to be ready        run: |          ./scripts/wait-for-services.sh      - name: Run integration tests        run: npm run test:integration      - name: Run E2E tests        run: npx playwright test      - name: Collect logs on failure        if: failure()        run: docker-compose -f docker-compose.test.yml logs      - name: Cleanup        if: always()        run: docker-compose -f docker-compose.test.yml down -v  # ==========================================  # STAGE 4: Security Scan  # ==========================================  security-scan:    needs: build-images    runs-on: ubuntu-latest    steps:      - name: Checkout code        uses: actions/checkout@v3      - name: Run Snyk security scan        uses: snyk/actions/node@master        env:          SNYK_TOKEN: ${{ secrets.SNYK_TOKEN }}        with:          args: --severity-threshold=high      - name: Run Trivy vulnerability scanner        uses: aquasecurity/trivy-action@master        with:          image-ref: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}/backend:${{ github.sha }}          format: 'sarif'          output: 'trivy-results.sarif'      - name: Upload Trivy results to GitHub Security        uses: github/codeql-action/upload-sarif@v2        with:          sarif_file: 'trivy-results.sarif'  # ==========================================  # STAGE 5: Deploy to Staging  # ==========================================  deploy-staging:    needs: [integration-tests, security-scan]    runs-on: ubuntu-latest    if: github.ref == 'refs/heads/develop'    environment:      name: staging      url: https://staging.qaero.ai    steps:      - name: Checkout code        uses: actions/checkout@v3      - name: Configure AWS credentials        uses: aws-actions/configure-aws-credentials@v2        with:          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}          aws-region: us-east-1      - name: Deploy to staging        run: |          ./scripts/deploy.sh staging      - name: Run smoke tests        run: |          ./scripts/smoke-test.sh https://staging.qaero.ai  # ==========================================  # STAGE 6: Deploy to Production  # ==========================================  deploy-production:    needs: [integration-tests, security-scan]    runs-on: ubuntu-latest    if: github.event_name == 'release'    environment:      name: production      url: https://qaero.ai    steps:      - name: Checkout code        uses: actions/checkout@v3      - name: Configure AWS credentials        uses: aws-actions/configure-aws-credentials@v2        with:          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID_PROD }}          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY_PROD }}          aws-region: us-east-1      - name: Deploy to production        run: |          ./scripts/deploy.sh production      - name: Run smoke tests        run: |          ./scripts/smoke-test.sh https://qaero.ai      - name: Notify Slack        uses: 8398a7/action-slack@v3        with:          status: ${{ job.status }}          text: 'Q-Aero deployment to production completed!'          webhook_url: ${{ secrets.SLACK_WEBHOOK }}```---### Monitoring Configuration#### Prometheus Configuration**prometheus/prometheus.yml:**```yaml# Prometheus configurationglobal:  scrape_interval: 15s  evaluation_interval: 15s  external_labels:    cluster: 'qaero-production'    replica: 'replica-1'# Alerting configurationalerting:  alertmanagers:    - static_configs:        - targets: ['alertmanager:9093']# Rule filesrule_files:  - '/etc/prometheus/rules/*.yml'# Scrape configurationsscrape_configs:  # Backend API  - job_name: 'backend'    static_configs:      - targets: ['backend:4000']    metrics_path: '/metrics'  # ML Inference Service  - job_name: 'ml-service'    static_configs:      - targets: ['ml-service:8000']    metrics_path: '/metrics'  # Physics Service  - job_name: 'physics-service'    static_configs:      - targets: ['physics-service:8001']    metrics_path: '/metrics'  # Quantum Service  - job_name: 'quantum-service'    static_configs:      - targets: ['quantum-service:8002']    metrics_path: '/metrics'  # FSI Service  - job_name: 'fsi-service'    static_configs:      - targets: ['fsi-service:8003']    metrics_path: '/metrics'  # MongoDB  - job_name: 'mongodb'    static_configs:      - targets: ['mongodb:27017']  # Redis  - job_name: 'redis'    static_configs:      - targets: ['redis:6379']  # Node Exporter (host metrics)  - job_name: 'node-exporter'    static_configs:      - targets: ['node-exporter:9100']  # cAdvisor (container metrics)  - job_name: 'cadvisor'    static_configs:      - targets: ['cadvisor:8080']  # NVIDIA GPU metrics (if available)  - job_name: 'nvidia-gpu'    static_configs:      - targets: ['nvidia-exporter:9445']```---### Scaling Strategies#### Horizontal Scaling (Docker Swarm)```bash# Initialize Docker Swarmdocker swarm init# Deploy stackdocker stack deploy -c docker-compose.production.yml qaero# Scale services dynamicallydocker service scale qaero_backend=5docker service scale qaero_ml-service=3docker service scale qaero_physics-service=4# Auto-scaling based on CPU usagedocker service update \  --replicas-max-per-node 2 \  --reserve-cpu 2 \  --reserve-memory 8G \  qaero_ml-service```---#### Kubernetes Deployment (Advanced)**k8s/deployment.yaml:**```yamlapiVersion: apps/v1kind: Deploymentmetadata:  name: ml-service  labels:    app: qaero    service: ml-inferencespec:  replicas: 3  selector:    matchLabels:      app: qaero      service: ml-inference  template:    metadata:      labels:        app: qaero        service: ml-inference    spec:      containers:      - name: ml-inference        image: ghcr.io/qaero/ml-inference:latest        ports:        - containerPort: 8000        resources:          requests:            memory: "16Gi"            cpu: "4"            nvidia.com/gpu: 1          limits:            memory: "24Gi"            cpu: "8"            nvidia.com/gpu: 1        env:        - name: CUDA_VISIBLE_DEVICES          value: "0"        - name: MODEL_PATH          value: "/models/surrogate_v1.onnx"        volumeMounts:        - name: model-cache          mountPath: /models          readOnly: true      volumes:      - name: model-cache        persistentVolumeClaim:          claimName: model-cache-pvc      nodeSelector:        gpu: nvidia-rtx---apiVersion: autoscaling/v2kind: HorizontalPodAutoscalermetadata:  name: ml-service-hpaspec:  scaleTargetRef:    apiVersion: apps/v1    kind: Deployment    name: ml-service  minReplicas: 2  maxReplicas: 10  metrics:  - type: Resource    resource:      name: cpu      target:        type: Utilization        averageUtilization: 70  - type: Resource    resource:      name: memory      target:        type: Utilization        averageUtilization: 80```---### Production Deployment Checklist**Pre-Deployment:**- [ ] All services built and pushed to container registry- [ ] Environment variables configured in `.env.production`- [ ] SSL certificates obtained (Let's Encrypt)- [ ] MongoDB secured with authentication- [ ] Redis password protected- [ ] Secrets stored in secure vault (AWS Secrets Manager, HashiCorp Vault)- [ ] Backup strategy configured (daily MongoDB backups)- [ ] Monitoring dashboards created in Grafana- [ ] Alert rules configured in Prometheus- [ ] Log aggregation configured (ELK stack)**Deployment:**- [ ] Deploy to staging environment first- [ ] Run smoke tests on staging- [ ] Monitor metrics for 24 hours on staging- [ ] Blue-green deployment to production- [ ] Run smoke tests on production- [ ] Monitor for anomalies (CPU, memory, errors)- [ ] Enable auto-scaling policies**Post-Deployment:**- [ ] Verify all services healthy (`docker ps`, `kubectl get pods`)- [ ] Check logs for errors (`docker logs`, `kubectl logs`)- [ ] Monitor dashboard for 72 hours- [ ] Document any issues encountered- [ ] Update runbook with lessons learned---## Risk Register### Technical Risks| Risk ID | Risk Description | Probability | Impact | Risk Score | Mitigation | Owner ||---------|-----------------|-------------|---------|-----------|-----------|-------|| **R-001** | GPU hardware failure | Medium | High | HIGH | Cloud backup, redundant GPU | DevOps || **R-002** | Quantum convergence failure | Medium | Medium | MEDIUM | Classical fallback, warm-start | Quantum || **R-003** | ML model overfitting | Medium | High | HIGH | Validation set, regularization | ML || **R-004** | Poor CFD data quality | Low | High | MEDIUM | Multiple sources, validation | Physics || **R-005** | Service integration complexity | High | High | CRITICAL | API contracts, mocking | Backend || **R-006** | Docker networking issues | Low | Medium | LOW | Early testing, documentation | DevOps || **R-007** | MongoDB performance bottleneck | Medium | Medium | MEDIUM | Indexing, sharding (future) | Backend || **R-008** | Frontend browser compatibility | Low | Low | LOW | Progressive enhancement | Frontend || **R-009** | Security breach (auth bypass) | Low | High | MEDIUM | Penetration testing, audits | Security || **R-010** | Scope creep | High | Medium | HIGH | Strict change control | PM |---### Project Risks| Risk ID | Risk Description | Probability | Impact | Risk Score | Mitigation | Owner ||---------|-----------------|-------------|---------|-----------|-----------|-------|| **R-011** | Key personnel departure | Low | High | MEDIUM | Documentation, knowledge sharing | PM || **R-012** | Budget overrun (cloud costs) | Medium | Medium | MEDIUM | Cost monitoring, resource limits | PM || **R-013** | Schedule delay | High | High | CRITICAL | Buffer time, critical path focus | PM || **R-014** | Requirement changes | Medium | Medium | MEDIUM | Change control board | PM || **R-015** | Stakeholder unavailability | Low | Low | LOW | Regular check-ins, async updates | PM |---### Mitigation Action Plan#### R-001: GPU Hardware Failure**Action Items:**1. Order backup GPU at project start (Week 1)2. Set up AWS GPU instance as cloud fallback (Week 2)3. Document GPU failover procedure (Week 2)4. Test failover quarterly**Trigger:** GPU fails health check or thermal throttling---#### R-003: ML Model Overfitting**Action Items:**1. Use 80/20 train/validation split with stratification2. Implement early stopping (patience=10 epochs)3. Add L2 regularization (weight_decay=1e-4)4. Use dropout (p=0.2) in hidden layers5. Track validation loss during training**Trigger:** Validation loss diverges from training loss by >20%---#### R-005: Service Integration Complexity (CRITICAL)**Action Items:**1. Define API contracts BEFORE implementation (Week 3)2. Use Pact for contract testing (Week 4)3. Mock services during development (Week 4)4. Dedicate Phase 6 entirely to integration (Weeks 20-22)5. Daily integration testing starting Week 76. Integration team lead assigned (Week 1)**Trigger:** Integration tests failing >3 days consecutively---#### R-013: Schedule Delay (CRITICAL)**Action Items:**1. Track critical path weekly (Gantt chart)2. 10% buffer time built into each phase3. Weekly status meetings with milestone tracking4. Escalate blockers within 24 hours5. Consider cutting non-critical features if delay >2 weeks**Trigger:** Any milestone delayed >1 week---## Deployment Strategy### Containerization**Docker Compose Architecture:**```yaml# docker-compose.ymlversion: '3.8'services:  # Frontend  frontend:    build: ./frontend    ports:      - "3000:3000"    environment:      - NEXT_PUBLIC_API_URL=http://backend:4000    depends_on:      - backend  # Backend  backend:    build: ./backend    ports:      - "4000:4000"    environment:      - MONGODB_URI=mongodb://mongodb:27017/qaero      - REDIS_URL=redis://redis:6379      - JWT_SECRET=${JWT_SECRET}    depends_on:      - mongodb      - redis      - ml-service      - physics-service      - quantum-service  # ML Inference Service (GPU)  ml-service:    build: ./services/ml_inference    ports:      - "8000:8000"    environment:      - MODEL_PATH=/models/surrogate_v1.onnx      - CUDA_VISIBLE_DEVICES=0    volumes:      - ./models:/models    deploy:      resources:        reservations:          devices:            - driver: nvidia              count: 1              capabilities: [gpu]  # Physics Service  physics-service:    build: ./services/physics    ports:      - "8001:8000"    volumes:      - ./cache:/cache  # Quantum Optimization Service  quantum-service:    build: ./services/quantum    ports:      - "8002:8000"    environment:      - QISKIT_BACKEND=aer_simulator  # FSI Service (Heavy computation)  fsi-service:    build: ./services/fsi    ports:      - "8003:8000"    volumes:      - ./simulations:/simulations  # MongoDB  mongodb:    image: mongo:7    ports:      - "27017:27017"    volumes:      - mongo-data:/data/db  # Redis  redis:    image: redis:7    ports:      - "6379:6379"  # NGINX Reverse Proxy  nginx:    image: nginx:latest    ports:      - "80:80"      - "443:443"    volumes:      - ./nginx.conf:/etc/nginx/nginx.conf    depends_on:      - frontend      - backendvolumes:  mongo-data:```---### Environment Configuration**Environment Variables (`.env`):**```bash# BackendNODE_ENV=productionPORT=4000MONGODB_URI=mongodb://mongodb:27017/qaeroREDIS_URL=redis://redis:6379JWT_SECRET=<generated-secret># ML ServiceMODEL_PATH=/models/surrogate_v1.onnxONNX_THREAD_POOL_SIZE=8CUDA_VISIBLE_DEVICES=0# Physics ServiceVLM_CACHE_SIZE=1000PANEL_MAX_PANELS=50000# Quantum ServiceQISKIT_BACKEND=aer_simulatorQAOA_MAX_LAYERS=5# FrontendNEXT_PUBLIC_API_URL=https://api.qaero.ai```---### Deployment Steps**Production Deployment:**```bash# 1. Clone repositorygit clone https://github.com/your-org/quantum-aero.gitcd quantum-aero# 2. Set environment variablescp .env.example .envnano .env  # Edit with production values# 3. Build imagesdocker-compose build# 4. Start servicesdocker-compose up -d# 5. Wait for health checks./scripts/wait-for-services.sh# 6. Initialize databasedocker-compose exec backend npm run db:migrate# 7. Verify deploymentcurl http://localhost/health```---### Monitoring & Observability**Prometheus Metrics:**```yaml# prometheus.ymlglobal:  scrape_interval: 15sscrape_configs:  - job_name: 'backend'    static_configs:      - targets: ['backend:4000']  - job_name: 'ml-service'    static_configs:      - targets: ['ml-service:8000']  - job_name: 'physics-service'    static_configs:      - targets: ['physics-service:8000']  - job_name: 'quantum-service'    static_configs:      - targets: ['quantum-service:8000']```**Grafana Dashboards:**1. **System Overview**   - Request rate (requests/sec)   - Error rate (%)   - P50/P95/P99 latency   - Active users2. **ML Service**   - Inference time distribution   - GPU utilization (%)   - Batch size distribution   - Model confidence scores3. **Quantum Service**   - QAOA convergence iterations   - Solution quality (energy)   - Circuit depth   - Classical fallback rate (%)4. **Database**   - Query latency   - Connection pool usage   - Slow queries   - Collection sizes---### Backup & Recovery**Automated Backup Schedule:**```bash# crontab -e0 2 * * * /opt/qaero/scripts/backup-mongodb.sh0 3 * * 0 /opt/qaero/scripts/backup-models.sh```**Backup Script (`scripts/backup-mongodb.sh`):**```bash#!/bin/bashDATE=$(date +%Y%m%d_%H%M%S)BACKUP_DIR=/backups/mongodbmkdir -p $BACKUP_DIRdocker-compose exec -T mongodb mongodump \  --out=/backup/mongo_$DATE \  --gzip# Upload to S3aws s3 cp $BACKUP_DIR/mongo_$DATE s3://qaero-backups/mongodb/# Retain last 30 days onlyfind $BACKUP_DIR -type d -mtime +30 -exec rm -rf {} \;```**Recovery Procedure:**```bash# 1. Stop servicesdocker-compose down# 2. Restore MongoDBdocker-compose up -d mongodbdocker-compose exec mongodb mongorestore \  --gzip \  /backup/mongo_20260115_020000# 3. Restart all servicesdocker-compose up -d# 4. Verify data integritydocker-compose exec backend npm run db:verify```---## Appendix### Glossary| Term | Definition ||------|------------|| **QAOA** | Quantum Approximate Optimization Algorithm - variational quantum algorithm for combinatorial optimization || **QUBO** | Quadratic Unconstrained Binary Optimization - optimization problem with binary variables || **VLM** | Vortex Lattice Method - potential flow method for lifting surfaces || **FSI** | Fluid-Structure Interaction - coupled simulation of fluid and solid mechanics || **GNN** | Graph Neural Network - neural network operating on graph-structured data || **ONNX** | Open Neural Network Exchange - portable ML model format || **ROM** | Reduced-Order Model - simplified model for fast computation || **DRS** | Drag Reduction System - adjustable rear wing on F1 cars |---### Acronyms- **API** - Application Programming Interface- **CFD** - Computational Fluid Dynamics- **CI/CD** - Continuous Integration / Continuous Deployment- **FSI** - Fluid-Structure Interaction- **GPU** - Graphics Processing Unit- **JWT** - JSON Web Token- **ML** - Machine Learning- **NISQ** - Noisy Intermediate-Scale Quantum- **REST** - Representational State Transfer- **UI/UX** - User Interface / User Experience- **VQE** - Variational Quantum Eigensolver---### References1. **Quantum-Aero F1 Prototype TASKS.md** - Detailed task breakdown2. **Quantum-Aero F1 Prototype PLAN.md** - High-level project plan3. **Quantum-Aero F1 Prototype DESIGN.md** - System architecture and design4. **Quantum-Aero F1 Prototype COMPLEX TRANSIENT.md** - Transient aerodynamics deep dive5. **Quantum-Aero F1 Prototype AEROELASTIC.md** - Aeroelastic analysis and quantum optimization6. **Quantum-Aero F1 Prototype TRANSIENT.md** - Additional transient aerodynamics7. **Genius_Evolution.md** - 2026-2027 technology roadmap---### Contact Information**Project Lead:** TBD**Email:** project-lead@qaero.ai**Slack:** #quantum-aero**Repository:** https://github.com/your-org/quantum-aero**Documentation:** https://docs.qaero.ai---### Change Log| Version | Date | Author | Changes ||---------|------|--------|---------|| 1.0 | 2025-11-24 | Claude Code | Initial integration document created |---### Approval Signatures| Role | Name | Signature | Date ||------|------|-----------|------|| **Project Lead** | ___________ | ___________ | _____ || **Technical Lead** | ___________ | ___________ | _____ || **QA Lead** | ___________ | ___________ | _____ || **Stakeholder** | ___________ | ___________ | _____ |---**End of Document**