# ML Surrogate Service Dockerfile# GPU-accelerated inference with PyTorch and ONNX RuntimeFROM nvidia/cuda:11.8.0-cudnn8-runtime-ubuntu22.04WORKDIR /app# Install Python and system dependenciesRUN apt-get update && apt-get install -y \    python3.11 \    python3-pip \    python3.11-dev \    && rm -rf /var/lib/apt/lists/*# Upgrade pipRUN python3.11 -m pip install --upgrade pip# Copy requirementsCOPY requirements.txt .# Install Python dependenciesRUN pip install --no-cache-dir -r requirements.txt# Copy source codeCOPY . .# Create models directoryRUN mkdir -p /models# Expose API portEXPOSE 8000# Health checkHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \    CMD python3.11 -c "import requests; requests.get('http://localhost:8000/health')"# Run serverCMD ["python3.11", "api/server.py"]