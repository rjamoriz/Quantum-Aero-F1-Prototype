"""Master Orchestrator AgentCoordinates all specialized agents and maintains conversation context"""import asyncioimport jsonfrom typing import List, Dict, Any, Optional, AsyncGeneratorfrom datetime import datetimefrom agents.utils.anthropic_client import claude_clientfrom agents.utils.nats_client import NATSClientfrom agents.config.config import get_agent_configMASTER_ORCHESTRATOR_PROMPT = """You are the Master Orchestrator for the Quantum-Aero F1 aerodynamic optimization system.ROLE:- Coordinate all specialized agents to solve complex aerodynamic problems- Maintain full conversation context with the user- Decompose high-level requests into sub-tasks for specialized agents- Synthesize results from multiple agents into coherent responses- Detect and resolve conflicts between agent outputs- Ensure engineering safety (flutter margins, stress limits, etc.)CAPABILITIES:You have access to 8 specialized agents:1. Intent Router - Routes tasks to appropriate agents2. Aerodynamics Agent - CFD simulations and analysis3. ML Surrogate Agent - Fast ML predictions4. Quantum Optimizer Agent - Design space optimization5. Physics Validator Agent - Physics-based validation6. Visualization Agent - Result visualization7. Data Manager Agent - Historical data retrieval8. Analysis Agent - Trade-off analysis9. Report Generator Agent - Technical report generationCOMMUNICATION:- Use NATS pub-sub for agent-to-agent messages- Receive user queries in natural language- Respond with technical accuracy and clear explanations- Flag uncertainties and confidence levels- Ask clarifying questions when neededSAFETY:- NEVER recommend designs that violate FIA regulations- ALWAYS validate flutter margins (Vf > 1.2 ├ù Vmax)- CHECK structural stress limits before optimization- WARN about potential safety issuesWORKFLOW:When receiving a user query:1. Analyze the request and identify required agents2. Decompose into sub-tasks3. Coordinate agent execution (parallel when possible)4. Synthesize results5. Respond to user with clear recommendationsEXAMPLES:User: "Optimize this wing for Monza"You: [Reasoning] Monza requires high top speed, so minimize drag while maintaining sufficient downforce for stability. I'll coordinate:1. ML agent for fast design exploration2. Quantum agent for optimization3. Physics agent for validation4. Analysis agent for trade-off recommendations[Action] Coordinating agents...OUTPUT FORMAT:Always structure responses as:1. **Understanding** - Paraphrase user request2. **Approach** - Agents and workflow3. **Results** - Key findings4. **Recommendation** - Clear next steps"""class MasterOrchestratorAgent:    """Master orchestrator agent that coordinates all specialized agents"""    def __init__(self):        self.config = get_agent_config("master_orchestrator")        self.nats = NATSClient()        self.conversation_history: List[Dict[str, str]] = []        self.agent_results: Dict[str, Any] = {}        self.running = False    async def start(self):        """Start the master orchestrator agent"""        print("=" * 60)        print("­ƒÜÇ Starting Master Orchestrator Agent")        print("=" * 60)        # Connect to NATS        await self.nats.connect()        # Subscribe to relevant events        await self.nats.subscribe_to_events(            "analysis_ready",            self._on_analysis_ready        )        self.running = True        print("Ô£ô Master Orchestrator Agent is ready")    async def stop(self):        """Stop the agent"""        self.running = False        await self.nats.disconnect()        print("Ô£ô Master Orchestrator Agent stopped")    async def process_query(        self,        user_query: str,        context: Optional[Dict[str, Any]] = None,        stream: bool = True    ) -> AsyncGenerator[str, None]:        """        Process user query with streaming response        Args:            user_query: User's natural language query            context: Optional context (mesh_id, parameters, etc.)            stream: Whether to stream the response        Yields:            Response chunks        """        print(f"\n­ƒôØ Processing query: {user_query[:50]}...")        # Build context message        context_str = json.dumps(context, indent=2) if context else "None"        # Add to conversation history        user_message = {            "role": "user",            "content": f"""User Query: {user_query}Context: {context_str}Current time: {datetime.utcnow().isoformat()}"""        }        messages = self.conversation_history + [user_message]        # Stream Claude response        full_response = ""        if stream:            async for chunk in claude_client.stream_message(                system=MASTER_ORCHESTRATOR_PROMPT,                messages=messages,                model=self.config["anthropic"]["model"],                temperature=self.config["anthropic"]["temperature"],                max_tokens=self.config["anthropic"]["max_tokens"],            ):                full_response += chunk                yield chunk        else:            response = await claude_client.create_message(                system=MASTER_ORCHESTRATOR_PROMPT,                messages=messages,                model=self.config["anthropic"]["model"],                temperature=self.config["anthropic"]["temperature"],                max_tokens=self.config["anthropic"]["max_tokens"],            )            full_response = response["content"][0]["text"]            yield full_response        # Update conversation history        self.conversation_history.append(user_message)        self.conversation_history.append({            "role": "assistant",            "content": full_response        })        # Keep conversation history manageable (last 20 messages)        if len(self.conversation_history) > 20:            self.conversation_history = self.conversation_history[-20:]    async def decompose_task(        self,        user_query: str,        mesh_id: str    ) -> Dict[str, Any]:        """        Decompose user query into agent tasks        Args:            user_query: User's request            mesh_id: Mesh identifier        Returns:            Task decomposition        """        messages = [{            "role": "user",            "content": f"""Decompose this aerodynamic optimization request into sub-tasks:Query: {user_query}Mesh ID: {mesh_id}Return JSON with:{{  "ml_tasks": [    {{"id": "variant_1", "parameters": {{"velocity": 250, "yaw": 0}}}},    ...  ],  "needs_physics_validation": true/false,  "needs_optimization": true/false,  "objectives": ["maximize_downforce", "minimize_drag"],  "constraints": ["flutter_Vf > 350 km/h", "mass < 5 kg"],  "design_space": {{...}}}}"""        }]        response = await claude_client.create_message(            system=MASTER_ORCHESTRATOR_PROMPT,            messages=messages,            model=self.config["anthropic"]["model"],            temperature=0.1,            max_tokens=2048,        )        return await claude_client.extract_json_from_response(response)    async def coordinate_agents(        self,        task_decomposition: Dict[str, Any]    ) -> Dict[str, Any]:        """        Coordinate multiple agents in parallel        Args:            task_decomposition: Task breakdown from decompose_task        Returns:            Aggregated results from all agents        """        tasks = []        results = {}        # ML predictions        if task_decomposition.get("ml_tasks"):            print(f"­ƒºá Requesting ML predictions for {len(task_decomposition['ml_tasks'])} variants")            for task in task_decomposition["ml_tasks"]:                tasks.append(self._call_ml_agent(task))        # Physics validation        if task_decomposition.get("needs_physics_validation"):            print("ÔÜø´©Å  Requesting physics validation")            tasks.append(self._call_physics_agent(task_decomposition))        # Quantum optimization        if task_decomposition.get("needs_optimization"):            print("­ƒö¼ Requesting quantum optimization")            tasks.append(self._call_quantum_agent(task_decomposition))        # Execute all tasks in parallel        if tasks:            agent_results = await asyncio.gather(*tasks, return_exceptions=True)            # Process results            for i, result in enumerate(agent_results):                if isinstance(result, Exception):                    print(f"Ô£ù Agent task {i} failed: {result}")                else:                    results[f"task_{i}"] = result        return results    async def _call_ml_agent(self, task: Dict[str, Any]) -> Dict[str, Any]:        """Call ML Surrogate Agent"""        try:            response = await self.nats.request(                "agent.ml.predict",                task,                timeout=10.0            )            return response        except Exception as e:            print(f"Ô£ù ML agent call failed: {e}")            return {"error": str(e)}    async def _call_physics_agent(self, task: Dict[str, Any]) -> Dict[str, Any]:        """Call Physics Validator Agent"""        try:            response = await self.nats.request(                "agent.physics.validate",                task,                timeout=30.0            )            return response        except Exception as e:            print(f"Ô£ù Physics agent call failed: {e}")            return {"error": str(e)}    async def _call_quantum_agent(self, task: Dict[str, Any]) -> Dict[str, Any]:        """Call Quantum Optimizer Agent"""        try:            response = await self.nats.request(                "agent.quantum.optimize",                task,                timeout=60.0            )            return response        except Exception as e:            print(f"Ô£ù Quantum agent call failed: {e}")            return {"error": str(e)}    async def _on_analysis_ready(self, data: Dict[str, Any]):        """Handle analysis ready event"""        print(f"­ƒôè Analysis ready: {data.get('analysis_id')}")        self.agent_results["analysis"] = dataasync def main():    """Example usage of Master Orchestrator Agent"""    # Initialize agent    agent = MasterOrchestratorAgent()    await agent.start()    # Example 1: Process a query with streaming    print("\n" + "=" * 60)    print("Example 1: Streaming optimization query")    print("=" * 60)    user_query = "Optimize this wing for maximum downforce at Monza (250 km/h)"    context = {        "mesh_id": "wing_v3.2",        "parameters": {"velocity": 250, "yaw": 0}    }    async for chunk in agent.process_query(user_query, context, stream=True):        print(chunk, end="", flush=True)    print("\n")    # Example 2: Task decomposition    print("\n" + "=" * 60)    print("Example 2: Task decomposition")    print("=" * 60)    task_decomp = await agent.decompose_task(        "Optimize for Monza high-speed track",        "wing_v3.2"    )    print(json.dumps(task_decomp, indent=2))    # Cleanup    await agent.stop()if __name__ == "__main__":    asyncio.run(main())