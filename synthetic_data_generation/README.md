# ğŸï¸ Synthetic Aerodynamic Dataset Generation for F1

**Multi-fidelity synthetic data generation system for F1-like aerodynamic configurations**

This system generates large-scale synthetic aerodynamic datasets using a multi-tier approach combining fast physics solvers, high-fidelity CFD, and ML augmentation.

---

## ğŸ“‹ Overview

### Multi-Tier Architecture

| Tier | Method | Speed | Samples | Use Case |
|------|--------|-------|---------|----------|
| **Tier 0** | Parametric Geometry | Instant | âˆ | Geometry generation |
| **Tier 1** | VLM/Panel | 5s/sample | 5k-50k | Bulk training data |
| **Tier 2** | Unsteady VLM | 30s/sample | 1k | Transient scenarios |
| **Tier 3** | RANS/URANS/LES | 1h/sample | 50-500 | Validation & calibration |
| **Tier 4** | ML Augmentation | 0.1s/sample | âˆ | Dataset expansion |

### Data Schema

Each sample contains:
- **Metadata**: `sample_id`, `timestamp`, `fidelity_tier`
- **Inputs**: `geometry_params` (16D vector), `flow_conditions`
- **Global Outputs**: `CL`, `CD`, `L/D`, `downforce_split`, `balance`
- **Field Outputs**: `Cp`, `Gamma`, `velocity_field`, `vorticity_field`
- **Time Series**: `CL(t)`, `CD(t)` for transient cases
- **Provenance**: `solver`, `mesh_size`, `runtime`, `convergence`

Storage:
- **Scalars**: JSON/Parquet (fast queries)
- **Fields**: HDF5/Zarr (compressed arrays)
- **Visualization**: VTK files for Paraview

---

## ğŸš€ Quick Start

### Local Installation

```bash
# Clone repository
cd synthetic_data_generation

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Generate small test dataset
python batch_orchestrator.py --tier1 100 --workers 4 --output ./test_dataset
```

### Docker (Recommended)

```bash
# Build image
docker build -t f1-synthetic-data .

# Run Tier 1 generation (5000 samples)
docker run --rm -v $(pwd)/data:/data f1-synthetic-data \
  python3 batch_orchestrator.py --tier1 5000 --workers 8 --output /data/tier1

# Or use docker-compose for multi-tier generation
docker-compose up tier1-generator
```

### Docker with GPU (for Tier 4 ML)

```bash
# Requires nvidia-docker
docker-compose up tier4-ml-augmentation
```

---

## ğŸ“Š Usage Examples

### 1. Generate Tier 1 Dataset (VLM)

```python
from batch_orchestrator import BatchOrchestrator

# Initialize orchestrator
orchestrator = BatchOrchestrator(
    output_dir="./my_dataset",
    n_workers=8  # Parallel workers
)

# Generate 1000 samples
samples = orchestrator.generate_tier1_batch(
    n_samples=1000,
    method='lhs'  # Latin Hypercube Sampling
)

# View statistics
stats = orchestrator.storage.get_statistics()
print(f"Mean CL: {stats['CL']['mean']:.3f}")
print(f"Mean L/D: {stats['L_over_D']['mean']:.2f}")
```

### 2. Custom Parameter Sampling

```python
from sampling_strategy import ParameterSampler
from schema import GeometryParameters

# Create sampler
sampler = ParameterSampler(seed=42)

# Generate 100 geometry configurations
geom_samples = sampler.generate_geometry_samples(
    n_samples=100,
    method='lhs'
)

# Generate flow conditions
flow_samples = sampler.generate_flow_conditions_samples(
    n_samples=100,
    V_inf_range=(50.0, 90.0),  # m/s
    yaw_range=(-5.0, 5.0),     # degrees
)

# Access first sample
print(geom_samples[0].to_dict())
```

### 3. Run Single VLM Simulation

```python
from tier1_vlm_solver import run_vlm_simulation
from schema import GeometryParameters, FlowConditions

# Define geometry
geom = GeometryParameters(
    main_plane_chord=100.0,      # cm
    main_plane_span=160.0,       # cm
    main_plane_angle_deg=5.0,    # deg
    flap1_angle_deg=10.0,
    flap2_angle_deg=15.0,
    endplate_height=300.0,       # mm
    rear_wing_chord=80.0,
    rear_wing_span=100.0,
    rear_wing_angle_deg=15.0,
    beam_wing_angle=8.0,
    floor_gap=25.0,              # mm
    diffuser_angle=18.0,
    diffuser_length=120.0,
    sidepod_width=45.0,
    sidepod_undercut=12.0,
    DRS_open=False
)

# Define flow conditions
flow = FlowConditions.standard_conditions(
    V_inf=70.0,        # m/s
    ground_gap=25.0    # mm
)

# Run simulation
sample = run_vlm_simulation(geom, flow, sample_index=0)

# Access results
print(f"CL: {sample.global_outputs.CL:.3f}")
print(f"CD: {sample.global_outputs.CD_total:.3f}")
print(f"L/D: {sample.global_outputs.L_over_D:.2f}")
print(f"Downforce: {sample.global_outputs.L:.0f} N")
print(f"Balance: {sample.global_outputs.balance:.1%} front")
```

### 4. Load and Analyze Dataset

```python
from batch_orchestrator import DatasetStorage
import numpy as np
import matplotlib.pyplot as plt

# Load dataset
storage = DatasetStorage("./my_dataset")
scalars = storage.load_scalars()

# Extract data
CL = [s['global_outputs']['CL'] for s in scalars]
CD = [s['global_outputs']['CD_total'] for s in scalars]
LD = [s['global_outputs']['L_over_D'] for s in scalars]

# Plot L/D vs CL
plt.figure(figsize=(10, 6))
plt.scatter(CL, LD, alpha=0.5)
plt.xlabel('CL')
plt.ylabel('L/D')
plt.title('Aerodynamic Efficiency Map')
plt.grid(True)
plt.savefig('efficiency_map.png')

# Load field data for specific sample
sample_id = scalars[0]['sample_id']
field_data = storage.load_field_data(sample_id)
Cp = field_data['Cp']
print(f"Pressure coefficient range: [{Cp.min():.2f}, {Cp.max():.2f}]")
```

---

## ğŸ—ï¸ Architecture

### File Structure

```
synthetic_data_generation/
â”œâ”€â”€ schema.py                  # Data schema definitions
â”œâ”€â”€ tier0_geometry.py          # Parametric geometry generator
â”œâ”€â”€ tier1_vlm_solver.py        # Fast VLM solver
â”œâ”€â”€ tier2_transient_solver.py  # Unsteady VLM (TODO)
â”œâ”€â”€ tier3_cfd_runner.py        # OpenFOAM/SU2 integration (TODO)
â”œâ”€â”€ tier4_ml_augmentation.py   # ML-based augmentation (TODO)
â”œâ”€â”€ sampling_strategy.py       # LHS and stratified sampling
â”œâ”€â”€ batch_orchestrator.py      # Parallel batch processing
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ Dockerfile                 # Container definition
â”œâ”€â”€ docker-compose.yml         # Multi-tier orchestration
â””â”€â”€ README.md                  # This file
```

### Parameter Space (16D)

**Front Wing** (6 params):
- `main_plane_chord`: 80-120 cm
- `main_plane_span`: 140-180 cm
- `main_plane_angle_deg`: -5 to 10Â°
- `flap1_angle_deg`: -5 to 20Â°
- `flap2_angle_deg`: -5 to 20Â°
- `endplate_height`: 200-400 mm

**Rear Wing** (4 params):
- `rear_wing_chord`: 60-100 cm
- `rear_wing_span`: 80-120 cm
- `rear_wing_angle_deg`: 5-25Â°
- `beam_wing_angle`: 0-15Â°

**Floor & Diffuser** (3 params):
- `floor_gap`: 10-50 mm
- `diffuser_angle`: 10-25Â°
- `diffuser_length`: 80-150 cm

**Body** (2 params):
- `sidepod_width`: 30-60 cm
- `sidepod_undercut`: 5-20 cm

**Control** (1 param):
- `DRS_open`: 0/1 (binary)

---

## ğŸ”¬ Validation & Quality

### Tier 1 (VLM) Validation

Expected ranges for F1-like configurations:
- **CL**: 2.5 - 4.5 (high downforce)
- **CD**: 0.7 - 1.2
- **L/D**: 3.0 - 6.0
- **Balance**: 35-45% front

### Convergence Checks

```python
# Check convergence
sample = run_vlm_simulation(geom, flow)
assert sample.provenance.convergence_achieved
assert sample.provenance.runtime_seconds < 10.0  # Fast enough

# Physical bounds
assert 2.0 < sample.global_outputs.CL < 5.0
assert 0.5 < sample.global_outputs.CD_total < 1.5
assert 0.3 < sample.global_outputs.balance < 0.5
```

### Mesh Independence

```python
# Test mesh refinement
for n_panels in [500, 1000, 2000, 5000]:
    sample = run_vlm_simulation(geom, flow)
    print(f"n_panels={n_panels}: CL={sample.global_outputs.CL:.3f}")
```

---

## ğŸ“ˆ Performance

### Tier 1 (VLM) Benchmarks

| Workers | Samples | Time | Samples/sec |
|---------|---------|------|-------------|
| 1 | 100 | 500s | 0.2 |
| 4 | 100 | 150s | 0.67 |
| 8 | 1000 | 1250s | 0.8 |
| 16 | 5000 | 5000s | 1.0 |

**Hardware**: AMD Ryzen 9 / Intel Xeon (16 cores)

### Estimated Generation Times

- **5k Tier 1 samples**: ~2 hours (8 workers)
- **1k Tier 2 samples**: ~8 hours (4 workers)
- **100 Tier 3 samples**: ~100 hours (16 cores CFD)
- **Total dataset**: ~110 hours (~5 days)

### Storage Requirements

- **Tier 1 (5k samples)**: ~2 GB (scalars + fields)
- **Tier 2 (1k samples)**: ~5 GB (with time series)
- **Tier 3 (100 samples)**: ~50 GB (full CFD fields)
- **Total**: ~60 GB

---

## ğŸ”§ Advanced Usage

### Distributed Computing with Dask

```python
from dask.distributed import Client
from batch_orchestrator import BatchOrchestrator

# Connect to Dask cluster
client = Client('dask-scheduler:8786')

# Run distributed generation
orchestrator = BatchOrchestrator(output_dir="./dataset")
orchestrator.generate_dataset(
    tier1_samples=10000,
    tier2_samples=2000,
    tier3_samples=200
)
```

### Custom Geometry Components

```python
from tier0_geometry import F1GeometryGenerator

# Extend generator
class CustomF1Generator(F1GeometryGenerator):
    def generate_custom_component(self):
        # Add your custom geometry
        pass

# Use custom generator
generator = CustomF1Generator(params)
mesh = generator.generate_complete_geometry()
```

### Integration with ML Training

```python
import torch
from torch.utils.data import Dataset, DataLoader

class AeroDataset(Dataset):
    def __init__(self, dataset_dir):
        self.storage = DatasetStorage(dataset_dir)
        self.scalars = self.storage.load_scalars()
    
    def __len__(self):
        return len(self.scalars)
    
    def __getitem__(self, idx):
        sample = self.scalars[idx]
        
        # Input: geometry parameters
        geom_vec = np.array(list(sample['geometry_params'].values()))
        
        # Output: aerodynamic coefficients
        CL = sample['global_outputs']['CL']
        CD = sample['global_outputs']['CD_total']
        
        return torch.tensor(geom_vec), torch.tensor([CL, CD])

# Create DataLoader
dataset = AeroDataset("./my_dataset")
loader = DataLoader(dataset, batch_size=32, shuffle=True)

# Train surrogate model
for geom_batch, aero_batch in loader:
    # Your training loop
    pass
```

---

## ğŸ› Troubleshooting

### Common Issues

**1. Slow VLM solve**
```python
# Reduce mesh resolution
generator = F1GeometryGenerator(params)
# Modify n_chord, n_span in generate_wing_section()
```

**2. Memory issues with large batches**
```python
# Reduce batch size or workers
orchestrator = BatchOrchestrator(n_workers=2)  # Reduce from 8
```

**3. HDF5 file corruption**
```python
# Use atomic writes
import h5py
with h5py.File('data.h5', 'w', libver='latest') as f:
    # Your writes
    f.flush()
```

---

## ğŸ“š References

### Theory
- Katz & Plotkin, "Low-Speed Aerodynamics" (VLM theory)
- Anderson, "Fundamentals of Aerodynamics"
- Drela, "Flight Vehicle Aerodynamics" (panel methods)

### Tools
- [AeroSandbox](https://github.com/peterdsharpe/AeroSandbox) - VLM in Python
- [OpenFOAM](https://www.openfoam.com/) - CFD solver
- [SU2](https://su2code.github.io/) - CFD with adjoint
- [Paraview](https://www.paraview.org/) - Visualization

### F1 Aerodynamics
- Zhang et al., "Ground Effect Aerodynamics of Race Cars"
- Keogh et al., "The Aerodynamics of F1 Front Wings"
- Dominy, "Aerodynamics of Grand Prix Cars"

---

## ğŸ¤ Contributing

Contributions welcome! Areas for improvement:
- [ ] Tier 2: Unsteady VLM implementation
- [ ] Tier 3: OpenFOAM/SU2 automation
- [ ] Tier 4: VAE/GAN augmentation
- [ ] Aeroelastic coupling (FSI)
- [ ] Real-time visualization dashboard
- [ ] Uncertainty quantification

---

## ğŸ“„ License

MIT License - See LICENSE file

---

## ğŸ¯ Next Steps

1. **Generate Tier 1 dataset**: `python batch_orchestrator.py --tier1 5000`
2. **Validate results**: Check CL/CD ranges, visualize in Paraview
3. **Train surrogate**: Use dataset for ML model training
4. **Expand to Tier 2/3**: Add transient and CFD samples
5. **ML augmentation**: Train generative models for Tier 4

---

**Questions?** Open an issue or contact the team.

**Performance tip**: Use Docker with `--workers 8` on multi-core systems for 8x speedup!
