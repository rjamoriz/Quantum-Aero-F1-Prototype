apiVersion: apps/v1kind: Deploymentmetadata:  name: ml-surrogate  namespace: qaero  labels:    app: ml-surrogate    component: gpu-inferencespec:  replicas: 1  # GPU nodes typically limited  selector:    matchLabels:      app: ml-surrogate  template:    metadata:      labels:        app: ml-surrogate        component: gpu-inference    spec:      nodeSelector:        accelerator: nvidia-gpu      containers:      - name: ml-surrogate        image: qaero/ml-surrogate:latest        ports:        - containerPort: 8000          name: http        env:        - name: PYTHONUNBUFFERED          value: "1"        - name: CUDA_VISIBLE_DEVICES          value: "0"        - name: MODEL_PATH          value: "/models/aero_surrogate.onnx"        resources:          requests:            memory: "2Gi"            cpu: "1000m"            nvidia.com/gpu: 1          limits:            memory: "4Gi"            cpu: "2000m"            nvidia.com/gpu: 1        volumeMounts:        - name: models          mountPath: /models          readOnly: true        livenessProbe:          httpGet:            path: /health            port: 8000          initialDelaySeconds: 60          periodSeconds: 10        readinessProbe:          httpGet:            path: /health            port: 8000          initialDelaySeconds: 30          periodSeconds: 5      volumes:      - name: models        persistentVolumeClaim:          claimName: ml-models-pvc---apiVersion: v1kind: Servicemetadata:  name: ml-surrogate  namespace: qaerospec:  selector:    app: ml-surrogate  ports:  - port: 8000    targetPort: 8000    name: http  type: ClusterIP---apiVersion: v1kind: PersistentVolumeClaimmetadata:  name: ml-models-pvc  namespace: qaerospec:  accessModes:  - ReadOnlyMany  resources:    requests:      storage: 10Gi  storageClassName: fast-ssd